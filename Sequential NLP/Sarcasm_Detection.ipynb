{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xJkSsfyWD9l"
   },
   "source": [
    "## PART 2: Detect sarcasm for headlines by training and tuning a Bidirectional LSTM model on New headlines for Sarcasm detection data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kr0_1RgodxK",
    "outputId": "3c977d43-af94-471c-d3f2-8616f87cecf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries\n",
    "from google.colab import drive\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import  Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,BatchNormalization,Dropout,Bidirectional,RNN,Input\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qneOuuwzrnHX",
    "outputId": "41a04bf4-9dcf-418c-f6a5-68a90be83038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "upiayueF-Wrg"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('/content/drive/MyDrive/Great Learning/NLP/Assignment 11/glove.6B.zip') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWBukpmUAN5o"
   },
   "source": [
    "### Read and explore the data. Retain relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nB6ipWBJsvom"
   },
   "outputs": [],
   "source": [
    "#open and read the json file\n",
    "def parseJson(fname):\n",
    "    for line in open(fname, 'r'):\n",
    "        yield eval(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w6lXLmlds3Iy"
   },
   "outputs": [],
   "source": [
    "sarcasm_json= list(parseJson('/content/drive/MyDrive/Great Learning/NLP/Assignment 11/Sarcasm_Headlines_Dataset.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6gO2I7stxTA9"
   },
   "outputs": [],
   "source": [
    "sarcasm_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ak5oWlajxcOf"
   },
   "outputs": [],
   "source": [
    "#Convert the read json to Dataframe\n",
    "for i in range(len(sarcasm_json)):\n",
    "  sarcasm_df = sarcasm_df.append(pd.Series([sarcasm_json[i]['headline'],sarcasm_json[i]['is_sarcastic']]),ignore_index=True)\n",
    "sarcasm_df.columns = ['headline', 'is_sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "R4FmNNwNAE0U"
   },
   "outputs": [],
   "source": [
    "sarcasm_df[\"is_sarcastic\"] = sarcasm_df[\"is_sarcastic\"].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHgChUpC3MAg",
    "outputId": "e8497507-aba1-4e73-c3a5-645f7c69cd39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset : (26709, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Shape of the dataset :\",sarcasm_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LPY6CNwe4baF"
   },
   "outputs": [],
   "source": [
    "#Export to csv in order to use it in future.\n",
    "sarcasm_df.to_csv('/content/drive/MyDrive/Great Learning/NLP/Assignment 11/Sarcasm_Headlines_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BBrA7PQ2fCr",
    "outputId": "af583ca1-7946-459d-d66a-46b3e430e0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   headline      26709 non-null  object\n",
      " 1   is_sarcastic  26709 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 313.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#Columns and datatypes\n",
    "sarcasm_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "rWoX6gkC2Wz0",
    "outputId": "d20d5d4b-9947-4066-985c-d0f15a07fe24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3008b2a9d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Distribution of target column\n",
    "sns.countplot(sarcasm_df['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2yLVNNtZ4gL0",
    "outputId": "a32d7a24-842c-4788-c1d3-e662beb0c0d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14985\n",
       "1    11724\n",
       "Name: is_sarcastic, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From the countplot above, we can see that values for is_sarcastic is fairly balanced.\n",
    "pd.Series(sarcasm_df['is_sarcastic']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfiOL1MRAmOJ"
   },
   "source": [
    "###  Get length of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qrHx7oiOBKNA"
   },
   "outputs": [],
   "source": [
    "#count of characters headlines\n",
    "sarcasm_df['charlength']  = sarcasm_df['headline'].str.len()\n",
    "#Count of words in headline\n",
    "sarcasm_df['wordsLength']=  sarcasm_df['headline'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "zySQZX9FFA0f",
    "outputId": "c9c93901-9732-4ccc-a1c1-073705831569"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>charlength</th>\n",
       "      <th>wordsLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>advancing the world's women</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the fascinating case for eating lab-grown meat</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this ceo will send your kids to school, if you...</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>top snake handler leaves sinking huckabee camp...</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>friday's morning email: inside trump's presser...</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  ...  wordsLength\n",
       "0  former versace store clerk sues over secret 'b...  ...           12\n",
       "1  the 'roseanne' revival catches up to our thorn...  ...           14\n",
       "2  mom starting to fear son's web series closest ...  ...           14\n",
       "3  boehner just wants wife to listen, not come up...  ...           13\n",
       "4  j.k. rowling wishes snape happy birthday in th...  ...           11\n",
       "5                        advancing the world's women  ...            4\n",
       "6     the fascinating case for eating lab-grown meat  ...            7\n",
       "7  this ceo will send your kids to school, if you...  ...           14\n",
       "8  top snake handler leaves sinking huckabee camp...  ...            7\n",
       "9  friday's morning email: inside trump's presser...  ...            9\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print dataframe with charlength and wordslength\n",
    "sarcasm_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nQY_bE2Apq4"
   },
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mU44ypTl-PbT"
   },
   "outputs": [],
   "source": [
    "\n",
    "max_word_freq = 20000    #the maximum number of words to keep, based on word frequency\n",
    "max_len = 200          #Length for padding word sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSb3GC7rA2pw"
   },
   "source": [
    "###  Get indices for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NzVXV4QCTAkz"
   },
   "outputs": [],
   "source": [
    "#Clean data\n",
    "Words=[]\n",
    "\n",
    "wnLemm = WordNetLemmatizer()\n",
    "def cleanData(cleanTxt):\n",
    "  cleanTxt=re.sub('[0-9]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[\\'\\\"\\.\\,(){}]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[!@\\*?:;#\\$\\%^&~]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[+-\\/X*]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[\\[\\]=<>]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[<<>>_*]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[^a-zA-Z]',\" \",cleanTxt)\n",
    "  cleanTxt=cleanTxt.lower()\n",
    "  #words_token = cleanTxt.split()\n",
    "  #words = [wnLemm.lemmatize(word) for word in words_token  if not word  in set(stopwords.words('english'))] \n",
    "  #Words.extend(words)\n",
    "  #words = \" \".join(words)\n",
    "  return cleanTxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8Yyt2v-GTw1z"
   },
   "outputs": [],
   "source": [
    "sarcasm_df['headlines_clean']=sarcasm_df['headline'].apply(cleanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "lM-qmYRDvIlN"
   },
   "outputs": [],
   "source": [
    "features=sarcasm_df['headlines_clean']\n",
    "labels= sarcasm_df['is_sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4SfxFoIjvKli"
   },
   "outputs": [],
   "source": [
    "#Vectorize the text corpus by converting them to sequence of numbers. Fit the features and get the indice/number associated with each word in the sequence\n",
    "tokenizer = Tokenizer(num_words=max_word_freq,  lower=True, char_level=False, oov_token=None, document_count=0)\n",
    "tokenizer.fit_on_texts(features)\n",
    "sequences = tokenizer.texts_to_sequences(features)\n",
    "#Pad the vectorized sequences to make them all of equal lengths\n",
    "X_feat_seq = pad_sequences(sequences, truncating='post', maxlen=max_len)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t94YTyxgGng0",
    "outputId": "d2e67132-53f0-4211-febd-0719690775f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cleaned Headline : the  roseanne  revival catches up to our thorny political mood  for better and worse\n",
      "Word indices :  [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    3 8131 3338 2760   24    1  160 8132  402 2913\n",
      "    6  246    9  987]\n",
      "\n",
      "cleaned Headline : mom starting to fear son s web series closest thing she will have to grandchild\n",
      "Word indices :  [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0   123   844     1   822   224     4  2090\n",
      "   581  4621   208    89    41    49     1 10221]\n",
      "\n",
      "cleaned Headline : boehner just wants wife to listen  not come up with alternative debt reduction ideas\n",
      "Word indices :  [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0 1334   39  217  348    1 1686   31  307   24   10\n",
      " 2914 1387 6762  886]\n",
      "\n",
      "cleaned Headline : j k  rowling wishes snape happy birthday in the most magical way\n",
      "Word indices :  [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0   743   567  3854   915\n",
      " 10222   557   558     5     3    97  1257    95]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Print headlines and their vectorized form\n",
    "for i in range(1,5):\n",
    "  print(\"\\ncleaned Headline :\",features[i])\n",
    "  print(\"Word indices : \",X_feat_seq[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYiDYAkkBEro"
   },
   "source": [
    "###  Create features and labels.Split them into 70:30 train-test ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "fVdc61ZMCQvE"
   },
   "outputs": [],
   "source": [
    "X_feat_seq     #Features\n",
    "label_arr=np.array(labels)   #Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "lF_PhlGC7l2r"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_feat_seq,label_arr,random_state=42,test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqoKyU4V6EvT"
   },
   "source": [
    "### 7. Create a weight matrix using GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "r3FBbWUeX_Px"
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "\n",
    "#Read the pre-trained glove embeddings. For each line, each line containing the word and their embedding, take the coefficients and map it to their words in dictionary.\n",
    "\n",
    "f = open('/content/glove.6B.50d.txt')\n",
    "\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "# create a weight matrix for words in headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "ierfmJ8SI9hL"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 50))   #we have used 50 columns for zero matrix since the glove embedding matrix we have created above has 50 dimensions.\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  embedding_vector = embeddings_index.get(word)\n",
    "  if embedding_vector is not None:\n",
    "    embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-c4U9Bb7Y4Y"
   },
   "source": [
    "### Define , compile and fit a Bidirectional LSTM model.Check the validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "2MLBazJlCERg"
   },
   "outputs": [],
   "source": [
    "#Define the model, compile and fit it. Calculate the validation accuracy. Return the fit model and validation accuracy.\n",
    "def SarcasmLSTMModel(epoch):\n",
    "  modelLSTM= Sequential()\n",
    "  modelLSTM.add(Input(shape=(max_len) ))\n",
    "\n",
    "  modelLSTM.add(Embedding(vocab_size,50,weights=[embedding_matrix],input_length=max_len))\n",
    "  modelLSTM.add(Bidirectional(LSTM(128)))\n",
    "\n",
    "  #modelNN.add(Bidirectional(LSTM(64,return_sequences=True)))\n",
    "  modelLSTM.add(BatchNormalization())\n",
    "  modelLSTM.add(Dropout(0.3))\n",
    "\n",
    "  modelLSTM.add(Dense(128,activation='relu',kernel_initializer='glorot_normal'))\n",
    "  modelLSTM.add(Dense(64,activation='relu',kernel_initializer='glorot_normal'))\n",
    "  modelLSTM.add(BatchNormalization())\n",
    "  modelLSTM.add(Dropout(0.3))\n",
    "\n",
    "  modelLSTM.add(Dense(1,activation='sigmoid',kernel_initializer='glorot_normal'))\n",
    "  checkpoint1 = ModelCheckpoint(\"/content/drive/MyDrive/Great Learning/NLP/Assignment 11/Sarcasm_model.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True)\n",
    "  modelLSTM.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "  history = modelLSTM.fit(X_train, y_train, batch_size=64, epochs=epoch, verbose=1,validation_split=0.2,callbacks=[checkpoint1])\n",
    "  #acc=modelLSTM.evaluate(X_test,y_test)\n",
    " \n",
    "  return modelLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4wXTI1MqneR",
    "outputId": "f1572608-5d8a-4628-d888-1082c977032e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/10\n",
      "234/234 [==============================] - 178s 738ms/step - loss: 0.6583 - accuracy: 0.6726 - val_loss: 0.5276 - val_accuracy: 0.7757\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77567, saving model to /content/drive/MyDrive/Great Learning/NLP/Assignment 11/Sarcasm_model.hdf5\n",
      "Epoch 2/10\n",
      "234/234 [==============================] - 172s 734ms/step - loss: 0.4397 - accuracy: 0.8015 - val_loss: 0.4760 - val_accuracy: 0.7882\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.77567 to 0.78824, saving model to /content/drive/MyDrive/Great Learning/NLP/Assignment 11/Sarcasm_model.hdf5\n",
      "Epoch 3/10\n",
      "234/234 [==============================] - 171s 730ms/step - loss: 0.3455 - accuracy: 0.8497 - val_loss: 0.3500 - val_accuracy: 0.8471\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78824 to 0.84706, saving model to /content/drive/MyDrive/Great Learning/NLP/Assignment 11/Sarcasm_model.hdf5\n",
      "Epoch 4/10\n",
      "234/234 [==============================] - 171s 731ms/step - loss: 0.2907 - accuracy: 0.8787 - val_loss: 0.3960 - val_accuracy: 0.8417\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.84706\n",
      "Epoch 5/10\n",
      "234/234 [==============================] - 170s 729ms/step - loss: 0.2427 - accuracy: 0.8993 - val_loss: 0.3250 - val_accuracy: 0.8607\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.84706 to 0.86070, saving model to /content/drive/MyDrive/Great Learning/NLP/Assignment 11/Sarcasm_model.hdf5\n",
      "Epoch 6/10\n",
      "234/234 [==============================] - 173s 738ms/step - loss: 0.2025 - accuracy: 0.9192 - val_loss: 0.3644 - val_accuracy: 0.8636\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.86070 to 0.86364, saving model to /content/drive/MyDrive/Great Learning/NLP/Assignment 11/Sarcasm_model.hdf5\n",
      "Epoch 7/10\n",
      "234/234 [==============================] - 172s 734ms/step - loss: 0.1949 - accuracy: 0.9226 - val_loss: 0.5891 - val_accuracy: 0.8059\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.86364\n",
      "Epoch 8/10\n",
      "234/234 [==============================] - 172s 734ms/step - loss: 0.1453 - accuracy: 0.9454 - val_loss: 0.4493 - val_accuracy: 0.8545\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.86364\n",
      "Epoch 9/10\n",
      "234/234 [==============================] - 174s 744ms/step - loss: 0.1275 - accuracy: 0.9525 - val_loss: 0.4869 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.86364\n",
      "Epoch 10/10\n",
      "234/234 [==============================] - 170s 728ms/step - loss: 0.1075 - accuracy: 0.9609 - val_loss: 0.4001 - val_accuracy: 0.8682\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.86364 to 0.86818, saving model to /content/drive/MyDrive/Great Learning/NLP/Assignment 11/Sarcasm_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "model= SarcasmLSTMModel(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XApxaRO-Xkf",
    "outputId": "940adfbc-f83e-4768-9cb8-5afeea9037ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 23s 90ms/step - loss: 0.3881 - accuracy: 0.8722\n",
      "test set accuracy : [0.38812756538391113, 0.8722076416015625]\n"
     ]
    }
   ],
   "source": [
    "#Print the test accuracy\n",
    "print(\"test set accuracy :\",model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnHnBQ9HE7wG",
    "outputId": "fc02cbaa-8c1b-42ee-aebe-a373122e05f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#Predict  sarcastic detection for test set\n",
    "predict=model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Y4_Jyl4uALuO"
   },
   "outputs": [],
   "source": [
    "#Convert the word indices to its word sentences for test set\n",
    "X_test_texts= tokenizer.sequences_to_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2RwsjD-FIrN",
    "outputId": "849e7da7-c12b-4b57-fe5e-9132a1b12e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions \n",
      "\n",
      "Statement : teen runaway starts new high paying career\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 1\n",
      "\n",
      "Statement : fcc votes to undo key roadblocks to media company consolidation\n",
      "\n",
      "Acutal Sarcasm value : 0\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : sniper school gets to have class on roof today\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 1\n",
      "\n",
      "Statement : star wars fan all\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : reid warren meet with progressive groups ahead of looming government shutdown\n",
      "\n",
      "Acutal Sarcasm value : 0\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : california lt governor gavin newsom should run for president\n",
      "\n",
      "Acutal Sarcasm value : 0\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : apparently fire marshal wasn t just being a dick\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : new study finds solving every single personal problem reduces anxiety\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 1\n",
      "\n",
      "Statement : a way to win election talk with lake\n",
      "\n",
      "Acutal Sarcasm value : 0\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : why one biologist doesn t believe the g spot is a myth\n",
      "\n",
      "Acutal Sarcasm value : 0\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : area apartment have no clear goal\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 1\n",
      "\n",
      "Statement : samsung profit forecast after pulling plug on note smartphone\n",
      "\n",
      "Acutal Sarcasm value : 0\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : these of america s fastest growing cities will make your jaw drop\n",
      "\n",
      "Acutal Sarcasm value : 0\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : taylor swift mourns death of boyfriend christopher dorner\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 1\n",
      "\n",
      "Statement : people cannot get over the way trump described frederick douglass\n",
      "\n",
      "Acutal Sarcasm value : 0\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : pope francis speaks to bishops on gay marriage and families in philadelphia\n",
      "\n",
      "Acutal Sarcasm value : 0\n",
      "Predicted Sarcasm value : 0\n",
      "\n",
      "Statement : woman shows hairstylist example of haircut she wants\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 1\n",
      "\n",
      "Statement : accidentally closing browser window with tabs open presents rare chance at new life\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 1\n",
      "\n",
      "Statement : everyone unaware how much freshman doing keg stand secretly misses his parents\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 1\n",
      "\n",
      "Statement : police find adorable little skeleton\n",
      "\n",
      "Acutal Sarcasm value : 1\n",
      "Predicted Sarcasm value : 1\n"
     ]
    }
   ],
   "source": [
    "#Print Headline, the actual value for sarcasm and the predicted value for sarcasm.\n",
    "print(\"Predictions \")\n",
    "for i in range(100,120):\n",
    "  print(\"\\nStatement :\", X_test_texts[i])\n",
    "  print(\"\\nAcutal Sarcasm value :\",y_test[i])\n",
    "  print(\"Predicted Sarcasm value :\",predict[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeKr59d6T9WZ"
   },
   "source": [
    "### OBSERVATIONS/CONCLUSIONS:\n",
    "1. For the sarcasm data, we were able to clean headline,create word embeddings using tokenizer from keras and associate indices for each word. We have created weight matrix to be fed to Bidirectional LSTM model using glove embeddings.We were able to train , tune and predict this model using several combinations of hyperparameters.\n",
    "2. The accuracy achieved for the LSTM model to detect sarscam in headlines is 87.22%.\n",
    "3. Out of 20 predicted values, model was able to correctly predict 18 values."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sarcasm_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
