{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "natSrVRK9ASA"
   },
   "source": [
    "## Part 2 : Implement a chatot using chatbot corpus for Olympus customer support "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUK516Uk9Mcm"
   },
   "source": [
    "###### We will implement semi-rule based ,machine learning based chatbot . We will split the corpus into intents/patterns, tags and responses. Intents/patterns will act  our independent variables whereas tags will be our dependent variable. We will preprocess, tokenize and vectorize our patterns using Bag of words and keras tokenizer and attempt to predict the tags. Based on tags,random responses will be picked and produced to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlDwIajPufQl",
    "outputId": "4fe24a59-a321-437e-ca15-61db7e57f4ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import nltk\n",
    "from nltk.chat.util import Chat,reflections\n",
    "from google.colab import  drive\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "from nltk import word_tokenize\n",
    "import tensorflow\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras import Model,Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout,Input,Embedding,Flatten,BatchNormalization,GlobalAveragePooling1D\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer,one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.initializers import GlorotNormal,GlorotUniform,HeNormal,HeUniform\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVf1gs8I6IJx",
    "outputId": "d6f55c1c-bde7-4e99-abc2-10bfd7aaaaa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "hIRcwAl96Toq"
   },
   "outputs": [],
   "source": [
    "path ='/content/drive/MyDrive/Great Learning/NLP/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ6te83E-HYU"
   },
   "source": [
    "#### 1. Import the chatbot corpus and split it into patterns ,tags and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "KYenUn2S58rh"
   },
   "outputs": [],
   "source": [
    "#Read chatbot corpus\n",
    "ChatBot_corpus= pd.read_json(path+'GL Bot.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_m6-qqYgR536",
    "outputId": "6c1e5ad6-436e-4af2-e7a2-cc9cae923d52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ChatBot_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "alcyOunN7GRT",
    "outputId": "03e36ad4-3686-4bf8-8769-a645561f2cf2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tag': 'Intro', 'patterns': ['hi', 'how are y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tag': 'Exit', 'patterns': ['thank you', 'tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'tag': 'Olympus', 'patterns': ['olympus', 'ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'tag': 'SL', 'patterns': ['i am not able to u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'tag': 'NN', 'patterns': ['what is deep learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'tag': 'Bot', 'patterns': ['what is your name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'tag': 'timings', 'patterns': ['when are your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'tag': 'Profane', 'patterns': ['what the hell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'tag': 'Ticket', 'patterns': ['my problem is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             intents\n",
       "0  {'tag': 'Intro', 'patterns': ['hi', 'how are y...\n",
       "1  {'tag': 'Exit', 'patterns': ['thank you', 'tha...\n",
       "2  {'tag': 'Olympus', 'patterns': ['olympus', 'ex...\n",
       "3  {'tag': 'SL', 'patterns': ['i am not able to u...\n",
       "4  {'tag': 'NN', 'patterns': ['what is deep learn...\n",
       "5  {'tag': 'Bot', 'patterns': ['what is your name...\n",
       "6  {'tag': 'timings', 'patterns': ['when are your...\n",
       "7  {'tag': 'Profane', 'patterns': ['what the hell...\n",
       "8  {'tag': 'Ticket', 'patterns': ['my problem is ..."
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatBot_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "n9uOplnF7Idx"
   },
   "outputs": [],
   "source": [
    "#Separate patterns/intents, tags and responses\n",
    "Words=[]\n",
    "X_feat=[]\n",
    "tags=[]\n",
    "response= []\n",
    "labels=[]\n",
    "tags_ext=[]\n",
    "for intent in ChatBot_corpus['intents']:\n",
    "  #print(intent)\n",
    "  for pattern in intent['patterns']:\n",
    "    #print(pattern)\n",
    "   \n",
    "    words = nltk.sent_tokenize(pattern)\n",
    "    \n",
    "    #print(words)\n",
    "    Words.extend(words)\n",
    "    X_feat.append(words)\n",
    "    tags.append(intent['tag'])\n",
    "    #print(\"words {}, tags : {}\".format(words,intent['tag']))\n",
    "    response.append(intent['responses'])\n",
    "  if intent['tag'] not in labels:\n",
    "    labels.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWUf2W_87hGP",
    "outputId": "748e9e74-0556-46b6-9ac9-fb5f8281ce4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxEheDAv4ko4",
    "outputId": "0a763161-0b8a-4392-c248-c6b3bd6bebe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot58bJ6m-Xfd"
   },
   "source": [
    "#### 2. Preprocess and vectorize patterns. One hot encode the tag column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "hQ-E0SEGU351"
   },
   "outputs": [],
   "source": [
    "#OneHotEncode the tags\n",
    "ohe = OneHotEncoder()\n",
    "tags=np.array(tags).reshape(-1,1)\n",
    "tags_ohe = ohe.fit_transform(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "Tw-tcFcVfQvW"
   },
   "outputs": [],
   "source": [
    "#Clean the patterns/intents text\n",
    "wnLemm = WordNetLemmatizer()\n",
    "import re\n",
    "#def cleanData(X):\n",
    "for i in range(len(Words)):\n",
    "  cleanTxt=Words[i]\n",
    "  cleanTxt=re.sub('[\\'\\\"\\.\\,(){}]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[!@\\*?:;#\\$\\%^&~]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[+-\\/X*]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[\\[\\]=<>]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[<<>>_*]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[^a-zA-Z]',\" \",cleanTxt)\n",
    "  cleanTxt=cleanTxt.lower()\n",
    "  words_token = cleanTxt.split()\n",
    "  w = [wnLemm.lemmatize(word) for word in words_token] \n",
    "  w = \" \".join(w)\n",
    "  Words[i]=w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "dAUX2R4xSp58"
   },
   "outputs": [],
   "source": [
    "#Vectoization of split intents using Bag of words\n",
    "bow=CountVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "rnd_os=SMOTE(k_neighbors=6)\n",
    "def implementCountVectorizer(Words):\n",
    "  \n",
    "  features_bow= bow.fit_transform(Words).todense()\n",
    "  X_feat_os,tags_ohe_os= rnd_os.fit_resample(features_bow,tags_ohe.todense())\n",
    "  X_train,X_test,y_train,y_test=train_test_split(X_feat_os,tags_ohe_os,random_state=42,test_size=0.30)\n",
    "  return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HqWbDew2WrYq"
   },
   "outputs": [],
   "source": [
    "#Vectorization using tokeniser\n",
    "vocab_size = 5000\n",
    "embedding_dim = 3000\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\"\n",
    "tokenizer = Tokenizer(num_words=vocab_size,oov_token=oov_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QMcNcHqSPHHW"
   },
   "outputs": [],
   "source": [
    "def implementTokenizer(Words):\n",
    "  tokenizer.fit_on_texts(Words)\n",
    "  sequences = tokenizer.texts_to_sequences(Words)\n",
    "  X_feat_seq = pad_sequences(sequences, truncating='pre', maxlen=max_len)\n",
    "  return X_feat_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rfn3azU4TkZi",
    "outputId": "c2a07b6b-0d42-4199-ef56-e935f7054a68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Split bag of words into train, test\n",
    "X_train_bow,X_test_bow,y_train_bow,y_test_bow=implementCountVectorizer(Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "kANz-5u9TswV"
   },
   "outputs": [],
   "source": [
    "X_feat_seq=implementTokenizer(Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFWIBxSjVyk7",
    "outputId": "9bdb784c-1099-407f-e8ed-ed84aaf98668"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['please help me',\n",
       " 'i am learner from',\n",
       " 'i belong to',\n",
       " 'aiml batch',\n",
       " 'aifl batch']"
      ]
     },
     "execution_count": 148,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Words[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4peJ7SaU-Mx",
    "outputId": "2787b357-b877-42a1-a86b-b2551252a8c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 126,  58,  50],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  13,  20, 288,  40],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  13, 289,   4],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 290, 127],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 291, 127]], dtype=int32)"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feat_seq[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "ZsTtrnajVCSo"
   },
   "outputs": [],
   "source": [
    "#Split tokenizer into train,test\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_feat_seq,tags_ohe.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PaFW6wq-mBr"
   },
   "source": [
    "#### 3. Create and tune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xz0ZjEny-sxY"
   },
   "source": [
    "##### 3.1. Create ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PpZNFzTXUab",
    "outputId": "777432e4-7751-4c8e-cac2-ada76337aa19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Form embedding matrix using glove embedding to be used in neural network\n",
    "embeddings_index = dict()\n",
    "f = open('/content/drive/MyDrive/Great Learning/NLP/glove.6B.50d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "3_GYjnAIXXyQ"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  embedding_vector = embeddings_index.get(word)\n",
    "  #print(len(embedding_vector))\n",
    "  if embedding_vector is not None:\n",
    "    embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "6oNb5IloweYb"
   },
   "outputs": [],
   "source": [
    "#Define ANN\n",
    "def train_test_model(Lambda,lr, epochs):\n",
    "  wt_initializer=HeNormal()\n",
    "  model = Sequential()\n",
    "  model.add(Input(shape=(max_len) ))\n",
    "  model.add(Embedding(vocab_size, 50,weights=[embedding_matrix]))\n",
    "  model.add(GlobalAveragePooling1D())\n",
    "  model.add(Flatten())\n",
    "  #model.add(Dropout(0.2))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(16, activation='relu',kernel_initializer=wt_initializer))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(9, activation='sigmoid',kernel_initializer=wt_initializer,kernel_regularizer=tensorflow.keras.regularizers.l2(Lambda)))\n",
    "  tsgd = SGD(learning_rate=lr)\n",
    "  # compile the model\n",
    "  model.compile(optimizer=tsgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.fit(X_train,y_train, epochs=epochs, batch_size=16, verbose=1,validation_split=0.20)\n",
    "  acc=model.evaluate(X_test,y_test)\n",
    "  return acc,model\n",
    "# summarize the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MT-ZHtaG4pKK",
    "outputId": "2060789d-1fc0-4ec3-9d4e-f356d124291a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 46ms/step - loss: 0.7010 - accuracy: 0.1448 - val_loss: 0.7052 - val_accuracy: 0.2449\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.1793 - val_loss: 0.7046 - val_accuracy: 0.2449\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7040 - accuracy: 0.0966 - val_loss: 0.7039 - val_accuracy: 0.2449\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7062 - accuracy: 0.1655 - val_loss: 0.7032 - val_accuracy: 0.2449\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.1862 - val_loss: 0.7026 - val_accuracy: 0.2449\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7066 - accuracy: 0.1310 - val_loss: 0.7020 - val_accuracy: 0.2449\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7000 - accuracy: 0.1379 - val_loss: 0.7013 - val_accuracy: 0.2449\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7055 - accuracy: 0.1310 - val_loss: 0.7007 - val_accuracy: 0.2449\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7005 - accuracy: 0.1379 - val_loss: 0.7000 - val_accuracy: 0.2449\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7040 - accuracy: 0.1517 - val_loss: 0.6994 - val_accuracy: 0.2449\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7017 - accuracy: 0.1310 - val_loss: 0.6987 - val_accuracy: 0.2449\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7000 - accuracy: 0.1586 - val_loss: 0.6981 - val_accuracy: 0.2449\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.1655 - val_loss: 0.6974 - val_accuracy: 0.2449\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7056 - accuracy: 0.1310 - val_loss: 0.6969 - val_accuracy: 0.2449\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6980 - accuracy: 0.1586 - val_loss: 0.6963 - val_accuracy: 0.2449\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6987 - accuracy: 0.0897 - val_loss: 0.6956 - val_accuracy: 0.2449\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6993 - accuracy: 0.1724 - val_loss: 0.6949 - val_accuracy: 0.2449\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6996 - accuracy: 0.1655 - val_loss: 0.6942 - val_accuracy: 0.2449\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.1724 - val_loss: 0.6936 - val_accuracy: 0.2449\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7003 - accuracy: 0.1448 - val_loss: 0.6929 - val_accuracy: 0.2449\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.3077\n",
      "try 1/5 Best_val_acc: [0.6700660586357117, 0.3076923191547394], lr: 0.0015032911010460352, Lambda: 2.103727458105338e-05\n",
      " \n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 48ms/step - loss: 0.7627 - accuracy: 0.0621 - val_loss: 0.7124 - val_accuracy: 0.0204\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7578 - accuracy: 0.0897 - val_loss: 0.7120 - val_accuracy: 0.0204\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7475 - accuracy: 0.1172 - val_loss: 0.7117 - val_accuracy: 0.0204\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7544 - accuracy: 0.1172 - val_loss: 0.7114 - val_accuracy: 0.0204\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7579 - accuracy: 0.0828 - val_loss: 0.7111 - val_accuracy: 0.0204\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7494 - accuracy: 0.1241 - val_loss: 0.7109 - val_accuracy: 0.0204\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7550 - accuracy: 0.0828 - val_loss: 0.7106 - val_accuracy: 0.0204\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7506 - accuracy: 0.0966 - val_loss: 0.7103 - val_accuracy: 0.0204\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7497 - accuracy: 0.0897 - val_loss: 0.7100 - val_accuracy: 0.0204\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7525 - accuracy: 0.0966 - val_loss: 0.7097 - val_accuracy: 0.0204\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7519 - accuracy: 0.1103 - val_loss: 0.7095 - val_accuracy: 0.0204\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7613 - accuracy: 0.0828 - val_loss: 0.7091 - val_accuracy: 0.0204\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7604 - accuracy: 0.1310 - val_loss: 0.7089 - val_accuracy: 0.0204\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7499 - accuracy: 0.1034 - val_loss: 0.7087 - val_accuracy: 0.0204\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7488 - accuracy: 0.0897 - val_loss: 0.7084 - val_accuracy: 0.0204\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7462 - accuracy: 0.0621 - val_loss: 0.7081 - val_accuracy: 0.0204\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7580 - accuracy: 0.0966 - val_loss: 0.7078 - val_accuracy: 0.0204\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7490 - accuracy: 0.1241 - val_loss: 0.7075 - val_accuracy: 0.0204\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7521 - accuracy: 0.0966 - val_loss: 0.7073 - val_accuracy: 0.0204\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7460 - accuracy: 0.1034 - val_loss: 0.7070 - val_accuracy: 0.0204\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7151 - accuracy: 0.0308\n",
      "try 2/5 Best_val_acc: [0.7151401042938232, 0.03076923079788685], lr: 0.00043472719519434293, Lambda: 3.021501919626715e-05\n",
      " \n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 47ms/step - loss: 0.6798 - accuracy: 0.0621 - val_loss: 0.6946 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6868 - accuracy: 0.0552 - val_loss: 0.6923 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6730 - accuracy: 0.0621 - val_loss: 0.6900 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6821 - accuracy: 0.0690 - val_loss: 0.6879 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6774 - accuracy: 0.0552 - val_loss: 0.6858 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6733 - accuracy: 0.0414 - val_loss: 0.6836 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6789 - accuracy: 0.0552 - val_loss: 0.6813 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6689 - accuracy: 0.0483 - val_loss: 0.6792 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6681 - accuracy: 0.0828 - val_loss: 0.6771 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6700 - accuracy: 0.0552 - val_loss: 0.6750 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6639 - accuracy: 0.0621 - val_loss: 0.6730 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6601 - accuracy: 0.0759 - val_loss: 0.6709 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6524 - accuracy: 0.0621 - val_loss: 0.6689 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6633 - accuracy: 0.0621 - val_loss: 0.6667 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6630 - accuracy: 0.0552 - val_loss: 0.6647 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6589 - accuracy: 0.0621 - val_loss: 0.6627 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6570 - accuracy: 0.0897 - val_loss: 0.6608 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.0828 - val_loss: 0.6589 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6530 - accuracy: 0.0552 - val_loss: 0.6568 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6444 - accuracy: 0.0552 - val_loss: 0.6550 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.0308\n",
      "try 3/5 Best_val_acc: [0.64063560962677, 0.03076923079788685], lr: 0.0046420734802134125, Lambda: 0.00015204704767238458\n",
      " \n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 48ms/step - loss: 0.6909 - accuracy: 0.0897 - val_loss: 0.6609 - val_accuracy: 0.1020\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.1034 - val_loss: 0.6562 - val_accuracy: 0.1020\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6903 - accuracy: 0.0966 - val_loss: 0.6515 - val_accuracy: 0.1020\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6713 - accuracy: 0.1034 - val_loss: 0.6468 - val_accuracy: 0.1020\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6802 - accuracy: 0.0828 - val_loss: 0.6422 - val_accuracy: 0.1020\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6736 - accuracy: 0.0690 - val_loss: 0.6376 - val_accuracy: 0.1020\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6741 - accuracy: 0.0621 - val_loss: 0.6331 - val_accuracy: 0.1020\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6592 - accuracy: 0.0966 - val_loss: 0.6287 - val_accuracy: 0.1020\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6488 - accuracy: 0.1310 - val_loss: 0.6241 - val_accuracy: 0.1020\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6577 - accuracy: 0.0621 - val_loss: 0.6198 - val_accuracy: 0.1020\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.1448 - val_loss: 0.6154 - val_accuracy: 0.1020\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6438 - accuracy: 0.1034 - val_loss: 0.6110 - val_accuracy: 0.1020\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6393 - accuracy: 0.0828 - val_loss: 0.6067 - val_accuracy: 0.1020\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6356 - accuracy: 0.0690 - val_loss: 0.6025 - val_accuracy: 0.1020\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6375 - accuracy: 0.0621 - val_loss: 0.5983 - val_accuracy: 0.1020\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6196 - accuracy: 0.0966 - val_loss: 0.5942 - val_accuracy: 0.1020\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6235 - accuracy: 0.0621 - val_loss: 0.5902 - val_accuracy: 0.1020\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6132 - accuracy: 0.1103 - val_loss: 0.5862 - val_accuracy: 0.1020\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6100 - accuracy: 0.1034 - val_loss: 0.5825 - val_accuracy: 0.1020\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6054 - accuracy: 0.0897 - val_loss: 0.5789 - val_accuracy: 0.1020\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.0923\n",
      "try 4/5 Best_val_acc: [0.5728405714035034, 0.0923076942563057], lr: 0.01281438670716511, Lambda: 0.0007536632761706544\n",
      " \n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 44ms/step - loss: 0.6819 - accuracy: 0.1172 - val_loss: 0.6027 - val_accuracy: 0.2449\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5772 - accuracy: 0.0966 - val_loss: 0.5192 - val_accuracy: 0.2449\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5122 - accuracy: 0.1379 - val_loss: 0.4620 - val_accuracy: 0.2449\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4642 - accuracy: 0.1448 - val_loss: 0.4235 - val_accuracy: 0.2449\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.1448 - val_loss: 0.3948 - val_accuracy: 0.2449\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4095 - accuracy: 0.1517 - val_loss: 0.3742 - val_accuracy: 0.2449\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.2138 - val_loss: 0.3587 - val_accuracy: 0.2449\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.1862 - val_loss: 0.3470 - val_accuracy: 0.2449\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3634 - accuracy: 0.2552 - val_loss: 0.3375 - val_accuracy: 0.3061\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.2345 - val_loss: 0.3300 - val_accuracy: 0.4490\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.2690 - val_loss: 0.3237 - val_accuracy: 0.4490\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3447 - accuracy: 0.2897 - val_loss: 0.3185 - val_accuracy: 0.4490\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3451 - accuracy: 0.2552 - val_loss: 0.3142 - val_accuracy: 0.4490\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3444 - accuracy: 0.2759 - val_loss: 0.3109 - val_accuracy: 0.4490\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3366 - accuracy: 0.2966 - val_loss: 0.3082 - val_accuracy: 0.4490\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3379 - accuracy: 0.3103 - val_loss: 0.3060 - val_accuracy: 0.4490\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3357 - accuracy: 0.2552 - val_loss: 0.3037 - val_accuracy: 0.4490\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3287 - accuracy: 0.2345 - val_loss: 0.3019 - val_accuracy: 0.4490\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3272 - accuracy: 0.3241 - val_loss: 0.3003 - val_accuracy: 0.4490\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3260 - accuracy: 0.2897 - val_loss: 0.2991 - val_accuracy: 0.4490\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.2154\n",
      "try 5/5 Best_val_acc: [0.3201870024204254, 0.2153846174478531], lr: 0.2964021513488951, Lambda: 5.2123344323690154e-05\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Tune ANN\n",
    "import math\n",
    "for i in range (1,6):\n",
    "    lr = math.pow(10, np.random.uniform(-4.0, 0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5,-3))\n",
    "    acc,model_sgd = train_test_model( Lambda,lr, 20)\n",
    "    print(\"try {0}/{1} Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n \".format(i,5 ,acc, lr, Lambda))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLTgHkg1IyJa",
    "outputId": "8b6bee0a-3b65-4cd5-cf01-956fee52d1e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 20, 50)            28800     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 459       \n",
      "=================================================================\n",
      "Total params: 29,459\n",
      "Trainable params: 29,359\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sgd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQkKrA3b_iNG",
    "outputId": "ff9f621a-1154-4318-bb08-1639fdfdcde2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.4124\n",
      "Trainings score : [0.3407194912433624, 0.41237112879753113]\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.3692\n",
      "Testing score : [0.3400239944458008, 0.3692307770252228]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainings score :\",model_sgd.evaluate(X_train, y_train))\n",
    "print(\"Testing score :\",model_sgd.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThhLHFIHtl53",
    "outputId": "795ba2e1-ef80-43ca-e836-1ee587111faa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 20ms/step - loss: 0.7333 - accuracy: 0.1806 - val_loss: 0.5463 - val_accuracy: 0.0513\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.2387 - val_loss: 0.4114 - val_accuracy: 0.2051\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.2968 - val_loss: 0.3435 - val_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.3355 - val_loss: 0.3135 - val_accuracy: 0.4103\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.3742 - val_loss: 0.2963 - val_accuracy: 0.4359\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3020 - accuracy: 0.3935 - val_loss: 0.2879 - val_accuracy: 0.4359\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.3806 - val_loss: 0.2820 - val_accuracy: 0.5128\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2855 - accuracy: 0.4000 - val_loss: 0.2810 - val_accuracy: 0.5128\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2786 - accuracy: 0.4129 - val_loss: 0.2782 - val_accuracy: 0.4615\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.4452 - val_loss: 0.2765 - val_accuracy: 0.4615\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.4452 - val_loss: 0.2753 - val_accuracy: 0.4615\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2612 - accuracy: 0.5161 - val_loss: 0.2731 - val_accuracy: 0.4615\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2618 - accuracy: 0.4774 - val_loss: 0.2714 - val_accuracy: 0.5128\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.5355 - val_loss: 0.2666 - val_accuracy: 0.5128\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.4581 - val_loss: 0.2652 - val_accuracy: 0.5128\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.5613 - val_loss: 0.2613 - val_accuracy: 0.5385\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.4774 - val_loss: 0.2593 - val_accuracy: 0.5385\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.5097 - val_loss: 0.2572 - val_accuracy: 0.5385\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2366 - accuracy: 0.5290 - val_loss: 0.2553 - val_accuracy: 0.5128\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.5548 - val_loss: 0.2549 - val_accuracy: 0.5128\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.5419 - val_loss: 0.2529 - val_accuracy: 0.6410\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2298 - accuracy: 0.5871 - val_loss: 0.2490 - val_accuracy: 0.5641\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.5226 - val_loss: 0.2480 - val_accuracy: 0.5897\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.6194 - val_loss: 0.2443 - val_accuracy: 0.5897\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2339 - accuracy: 0.5355 - val_loss: 0.2427 - val_accuracy: 0.5641\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2313 - accuracy: 0.6000 - val_loss: 0.2420 - val_accuracy: 0.5385\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2311 - accuracy: 0.5484 - val_loss: 0.2362 - val_accuracy: 0.5897\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2204 - accuracy: 0.5677 - val_loss: 0.2440 - val_accuracy: 0.4872\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2217 - accuracy: 0.6000 - val_loss: 0.2311 - val_accuracy: 0.6410\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.6065 - val_loss: 0.2371 - val_accuracy: 0.6154\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2174 - accuracy: 0.6000 - val_loss: 0.2275 - val_accuracy: 0.6154\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2149 - accuracy: 0.6452 - val_loss: 0.2224 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2141 - accuracy: 0.6065 - val_loss: 0.2292 - val_accuracy: 0.5128\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2023 - accuracy: 0.5871 - val_loss: 0.2170 - val_accuracy: 0.6923\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.6323 - val_loss: 0.2160 - val_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.6323 - val_loss: 0.2126 - val_accuracy: 0.6923\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.6516 - val_loss: 0.2118 - val_accuracy: 0.6154\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2057 - accuracy: 0.6258 - val_loss: 0.2195 - val_accuracy: 0.6923\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.5935 - val_loss: 0.2145 - val_accuracy: 0.5641\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.6710 - val_loss: 0.2046 - val_accuracy: 0.6410\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1948 - accuracy: 0.6581 - val_loss: 0.2036 - val_accuracy: 0.6923\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1983 - accuracy: 0.6258 - val_loss: 0.2043 - val_accuracy: 0.6410\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.6839 - val_loss: 0.2020 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2066 - accuracy: 0.6065 - val_loss: 0.2037 - val_accuracy: 0.6923\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1897 - accuracy: 0.6774 - val_loss: 0.1944 - val_accuracy: 0.6923\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.7032 - val_loss: 0.1913 - val_accuracy: 0.6923\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1841 - accuracy: 0.6903 - val_loss: 0.2051 - val_accuracy: 0.6410\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2005 - accuracy: 0.6387 - val_loss: 0.1963 - val_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1950 - accuracy: 0.6452 - val_loss: 0.1866 - val_accuracy: 0.6923\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.6968 - val_loss: 0.2041 - val_accuracy: 0.6154\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.6645 - val_loss: 0.2433 - val_accuracy: 0.5385\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1830 - accuracy: 0.6581 - val_loss: 0.1925 - val_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.7032 - val_loss: 0.1939 - val_accuracy: 0.6410\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1916 - accuracy: 0.6710 - val_loss: 0.1881 - val_accuracy: 0.6923\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.7355 - val_loss: 0.2086 - val_accuracy: 0.6154\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.7806 - val_loss: 0.1960 - val_accuracy: 0.6923\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1736 - accuracy: 0.6968 - val_loss: 0.2656 - val_accuracy: 0.5385\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1674 - accuracy: 0.7355 - val_loss: 0.2256 - val_accuracy: 0.5641\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1619 - accuracy: 0.7161 - val_loss: 0.2063 - val_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.7419 - val_loss: 0.1838 - val_accuracy: 0.7436\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1619 - accuracy: 0.7677 - val_loss: 0.2024 - val_accuracy: 0.6410\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.7419 - val_loss: 0.2032 - val_accuracy: 0.6154\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.7484 - val_loss: 0.2585 - val_accuracy: 0.5385\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1706 - accuracy: 0.7355 - val_loss: 0.2289 - val_accuracy: 0.6410\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.7419 - val_loss: 0.1922 - val_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.7871 - val_loss: 0.2236 - val_accuracy: 0.6410\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.8065 - val_loss: 0.2100 - val_accuracy: 0.6923\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 0.7806 - val_loss: 0.1964 - val_accuracy: 0.7179\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1605 - accuracy: 0.7548 - val_loss: 0.2548 - val_accuracy: 0.6154\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1766 - accuracy: 0.7419 - val_loss: 0.2150 - val_accuracy: 0.5897\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.7484 - val_loss: 0.2214 - val_accuracy: 0.6410\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.8323 - val_loss: 0.2168 - val_accuracy: 0.5897\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.7613 - val_loss: 0.1865 - val_accuracy: 0.7436\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1640 - accuracy: 0.7355 - val_loss: 0.1888 - val_accuracy: 0.7436\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.7355 - val_loss: 0.2107 - val_accuracy: 0.6923\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.7871 - val_loss: 0.2547 - val_accuracy: 0.6154\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.7806 - val_loss: 0.2216 - val_accuracy: 0.5641\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1590 - accuracy: 0.7355 - val_loss: 0.2449 - val_accuracy: 0.6154\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.7419 - val_loss: 0.2467 - val_accuracy: 0.6410\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.7871 - val_loss: 0.2289 - val_accuracy: 0.6154\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.7806 - val_loss: 0.2017 - val_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.7290 - val_loss: 0.2150 - val_accuracy: 0.6410\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.8000 - val_loss: 0.1990 - val_accuracy: 0.6667\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.7484 - val_loss: 0.2400 - val_accuracy: 0.6410\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.8129 - val_loss: 0.2225 - val_accuracy: 0.6923\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1238 - accuracy: 0.8645 - val_loss: 0.2267 - val_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.7355 - val_loss: 0.2928 - val_accuracy: 0.5897\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1358 - accuracy: 0.7935 - val_loss: 0.5537 - val_accuracy: 0.5385\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.8516 - val_loss: 0.2170 - val_accuracy: 0.7179\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1611 - accuracy: 0.7613 - val_loss: 0.2458 - val_accuracy: 0.7179\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1392 - accuracy: 0.8000 - val_loss: 0.2643 - val_accuracy: 0.6154\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1599 - accuracy: 0.7806 - val_loss: 0.3174 - val_accuracy: 0.6154\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1463 - accuracy: 0.7871 - val_loss: 0.2162 - val_accuracy: 0.6410\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.8000 - val_loss: 0.1807 - val_accuracy: 0.7179\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1644 - accuracy: 0.7097 - val_loss: 0.3147 - val_accuracy: 0.5641\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.8323 - val_loss: 0.2610 - val_accuracy: 0.6410\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1314 - accuracy: 0.8323 - val_loss: 0.2542 - val_accuracy: 0.6410\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.8194 - val_loss: 0.2421 - val_accuracy: 0.6410\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.7548 - val_loss: 0.1918 - val_accuracy: 0.7179\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.8581 - val_loss: 0.1967 - val_accuracy: 0.6923\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1839 - accuracy: 0.7385\n"
     ]
    }
   ],
   "source": [
    "scc,model_sgd=train_test_model(0.0003334509699429611 ,0.415988399710898,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceyTKA2LkmTI",
    "outputId": "585c4fbf-35da-4965-e5e0-bf3648bb89b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.8918\n",
      "Trainings score : [0.1110503077507019, 0.8917526006698608]\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.7385\n",
      "Testing score : [0.18387246131896973, 0.7384615540504456]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainings score :\",model_sgd.evaluate(X_train, y_train))\n",
    "print(\"Testing score :\",model_sgd.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "jllkkor_5fXP"
   },
   "outputs": [],
   "source": [
    "predict=model_sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "o7OwSGiKu_1-"
   },
   "outputs": [],
   "source": [
    "y_test_inv=ohe.inverse_transform(y_test)\n",
    "pred_inv= ohe.inverse_transform(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2U7RnPiUvMBv",
    "outputId": "04e188b5-813a-472f-85fe-18c8f480325b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual value :  ['SL']\n",
      "Predicted value : ['NN']\n",
      "\n",
      "Actual value :  ['NN']\n",
      "Predicted value : ['NN']\n",
      "\n",
      "Actual value :  ['Bot']\n",
      "Predicted value : ['Exit']\n",
      "\n",
      "Actual value :  ['SL']\n",
      "Predicted value : ['SL']\n",
      "\n",
      "Actual value :  ['timings']\n",
      "Predicted value : ['timings']\n",
      "\n",
      "Actual value :  ['Exit']\n",
      "Predicted value : ['Exit']\n",
      "\n",
      "Actual value :  ['NN']\n",
      "Predicted value : ['SL']\n",
      "\n",
      "Actual value :  ['SL']\n",
      "Predicted value : ['SL']\n",
      "\n",
      "Actual value :  ['Ticket']\n",
      "Predicted value : ['Intro']\n",
      "\n",
      "Actual value :  ['NN']\n",
      "Predicted value : ['NN']\n",
      "\n",
      "Actual value :  ['SL']\n",
      "Predicted value : ['SL']\n"
     ]
    }
   ],
   "source": [
    "#predict using ANN for 10 records from dataset\n",
    "for ind in range(10,21):\n",
    "  print(\"\\nActual value : \",y_test_inv[ind])\n",
    "  print(\"Predicted value :\",pred_inv[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dmg109z3ARy"
   },
   "source": [
    "##### 3.2 Create and tune machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "W97DtW-53NO7"
   },
   "outputs": [],
   "source": [
    "logRegression=LogisticRegression(C=1.0,penalty='l1',solver='liblinear',max_iter =100,multi_class='ovr')\n",
    "multiNomialNB =MultinomialNB()\n",
    "\n",
    "svm=SVC(C=1.0,kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "qmDErROrRHk1"
   },
   "outputs": [],
   "source": [
    "#Train and Tune Machine learning algorithms\n",
    "param_grid_rf ={'n_estimators':list(range(1,300)),'criterion':['gini','entropy'],'max_depth':list(range(1,100))}\n",
    "param_grid_decisionCl = {'criterion':['gini','entropy'],\n",
    "                         'splitter':['best','random'],\n",
    "                         'max_depth':list(range(1,200)),\n",
    "                         'max_features':['auto','log2'],\n",
    "                         'max_leaf_nodes':list(range(1,200))\n",
    "                        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "aed87NtVRSX1"
   },
   "outputs": [],
   "source": [
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(),param_grid_rf,n_iter=10,cv=5,verbose=1)\n",
    "rs_dcl = RandomizedSearchCV(DecisionTreeClassifier(),param_grid_decisionCl,n_iter=10,cv=5,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "zcX30hqMGEKQ"
   },
   "outputs": [],
   "source": [
    "#predict using BoW\n",
    "model_dict = {'logRegression: ':logRegression,\n",
    "              'MultinomialNB': multiNomialNB,\n",
    "              'svm':svm,\n",
    "              'RandomForest':rs_rf,\n",
    "              'decisionTree':rs_dcl\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8h1eYYPE39d2",
    "outputId": "8e09a337-9ca1-4c2f-b01d-d5b726556eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Model : logRegression: =======\n",
      "Accuracy :  0.32323232323232326\n",
      "classification_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.48      0.63        23\n",
      "           1       1.00      0.13      0.23        31\n",
      "           2       1.00      0.12      0.22        16\n",
      "           3       1.00      0.50      0.67        16\n",
      "           4       1.00      0.90      0.95        20\n",
      "           5       1.00      0.32      0.48        19\n",
      "           6       0.89      0.29      0.43        28\n",
      "           7       1.00      0.09      0.16        23\n",
      "           8       0.86      0.27      0.41        22\n",
      "\n",
      "   micro avg       0.96      0.33      0.49       198\n",
      "   macro avg       0.96      0.34      0.46       198\n",
      "weighted avg       0.96      0.33      0.45       198\n",
      " samples avg       0.33      0.33      0.33       198\n",
      "\n",
      "=======Model : MultinomialNB=======\n",
      "Accuracy :  0.3333333333333333\n",
      "classification_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.48      0.46        23\n",
      "           1       0.35      0.23      0.27        31\n",
      "           2       0.33      0.31      0.32        16\n",
      "           3       0.69      0.56      0.62        16\n",
      "           4       0.55      0.85      0.67        20\n",
      "           5       0.32      0.32      0.32        19\n",
      "           6       1.00      0.64      0.78        28\n",
      "           7       0.12      0.09      0.10        23\n",
      "           8       0.32      0.27      0.29        22\n",
      "\n",
      "   micro avg       0.46      0.41      0.43       198\n",
      "   macro avg       0.46      0.42      0.43       198\n",
      "weighted avg       0.47      0.41      0.43       198\n",
      " samples avg       0.35      0.41      0.36       198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Model : svm=======\n",
      "Accuracy :  0.21212121212121213\n",
      "classification_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.47        23\n",
      "           1       0.00      0.00      0.00        31\n",
      "           2       1.00      0.12      0.22        16\n",
      "           3       1.00      0.06      0.12        16\n",
      "           4       1.00      0.75      0.86        20\n",
      "           5       1.00      0.21      0.35        19\n",
      "           6       0.86      0.21      0.34        28\n",
      "           7       1.00      0.09      0.16        23\n",
      "           8       1.00      0.23      0.37        22\n",
      "\n",
      "   micro avg       0.98      0.21      0.35       198\n",
      "   macro avg       0.87      0.22      0.32       198\n",
      "weighted avg       0.82      0.21      0.31       198\n",
      " samples avg       0.21      0.21      0.21       198\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   22.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   32.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   34.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   13.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   23.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   31.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   20.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Model : RandomForest=======\n",
      "Accuracy :  0.3939393939393939\n",
      "classification_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76        23\n",
      "           1       1.00      0.35      0.52        31\n",
      "           2       1.00      0.44      0.61        16\n",
      "           3       1.00      0.25      0.40        16\n",
      "           4       1.00      0.85      0.92        20\n",
      "           5       1.00      0.37      0.54        19\n",
      "           6       0.89      0.29      0.43        28\n",
      "           7       1.00      0.09      0.16        23\n",
      "           8       1.00      0.27      0.43        22\n",
      "\n",
      "   micro avg       0.95      0.39      0.56       198\n",
      "   macro avg       0.97      0.40      0.53       198\n",
      "weighted avg       0.97      0.39      0.52       198\n",
      " samples avg       0.39      0.39      0.39       198\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: max_leaf_nodes 1 must be either None or larger than 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "=======Model : decisionTree=======\n",
      "Accuracy :  0.3484848484848485\n",
      "classification_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.60        23\n",
      "           1       0.88      0.23      0.36        31\n",
      "           2       0.86      0.38      0.52        16\n",
      "           3       0.71      0.31      0.43        16\n",
      "           4       0.74      0.85      0.79        20\n",
      "           5       0.58      0.37      0.45        19\n",
      "           6       0.93      0.50      0.65        28\n",
      "           7       0.67      0.09      0.15        23\n",
      "           8       0.83      0.23      0.36        22\n",
      "\n",
      "   micro avg       0.73      0.39      0.51       198\n",
      "   macro avg       0.75      0.39      0.48       198\n",
      "weighted avg       0.76      0.39      0.48       198\n",
      " samples avg       0.37      0.39      0.37       198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.5s finished\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for key,value in model_dict.items():\n",
    "  model=OneVsRestClassifier(value)\n",
    "  model.fit(X_train_bow,y_train_bow)\n",
    "  predict = model.predict(X_test_bow)\n",
    "  print(\"=======Model : {}=======\".format(key))\n",
    "  print(\"Accuracy : \",accuracy_score(y_test_bow,predict))\n",
    "  print(\"classification_report : \\n\",classification_report(y_test_bow,predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbSkt9-bRcma",
    "outputId": "21c968e9-e2d2-42d4-e2c6-07c6c5724a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   34.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.37373737373737376\n",
      "classification_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.65      0.77        23\n",
      "           1       1.00      0.32      0.49        31\n",
      "           2       1.00      0.38      0.55        16\n",
      "           3       0.80      0.25      0.38        16\n",
      "           4       1.00      0.80      0.89        20\n",
      "           5       1.00      0.32      0.48        19\n",
      "           6       0.90      0.32      0.47        28\n",
      "           7       1.00      0.09      0.16        23\n",
      "           8       1.00      0.27      0.43        22\n",
      "\n",
      "   micro avg       0.96      0.37      0.54       198\n",
      "   macro avg       0.96      0.38      0.51       198\n",
      "weighted avg       0.96      0.37      0.51       198\n",
      " samples avg       0.37      0.37      0.37       198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rs_rf.fit(X_train_bow,y_train_bow)\n",
    "predict_rs_rf = rs_rf.predict(X_test_bow)\n",
    "print(\"Accuracy : \",accuracy_score(y_test_bow,predict_rs_rf))\n",
    "print(\"classification_report : \\n\",classification_report(y_test_bow,predict_rs_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AE0IhNH-Sap-",
    "outputId": "cc30082a-471f-49b4-903c-13cdf79b167a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.43434343434343436\n",
      "classification_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71        23\n",
      "           1       0.81      0.42      0.55        31\n",
      "           2       0.70      0.44      0.54        16\n",
      "           3       0.56      0.31      0.40        16\n",
      "           4       0.89      0.80      0.84        20\n",
      "           5       0.86      0.32      0.46        19\n",
      "           6       0.84      0.57      0.68        28\n",
      "           7       1.00      0.09      0.16        23\n",
      "           8       0.86      0.27      0.41        22\n",
      "\n",
      "   micro avg       0.80      0.43      0.56       198\n",
      "   macro avg       0.81      0.43      0.53       198\n",
      "weighted avg       0.82      0.43      0.54       198\n",
      " samples avg       0.43      0.43      0.43       198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.6s finished\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rs_dcl.fit(X_train_bow,y_train_bow)\n",
    "predict_rs_dcl = rs_dcl.predict(X_test_bow)\n",
    "print(\"Accuracy : \",accuracy_score(y_test_bow,predict_rs_dcl))\n",
    "print(\"classification_report : \\n\",classification_report(y_test_bow,predict_rs_dcl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHjqPtaX8YYm"
   },
   "source": [
    "#### Comparing the accuracies of models, we observe that an ANN performs the best. So we will use ANN model for our chatBot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "id": "Dp779YpwNrhU"
   },
   "outputs": [],
   "source": [
    "#function to return processed string for Bagofwords if  \n",
    "def preprocessInputBow(inputStr):\n",
    "  inputStr=bow.transform([inputStr])\n",
    "  return inputStr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "I-SEu3EyS4ao"
   },
   "outputs": [],
   "source": [
    "#Function to return processed string using tokeniser for ANN\n",
    "def preprocessInput(inputStr):\n",
    "  inputStr= tokenizer.texts_to_sequences([inputStr])\n",
    "  inputStr=pad_sequences(inputStr, truncating='pre', maxlen=max_len)\n",
    "  return inputStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7GKEy5ag86mQ",
    "outputId": "8e94b30e-f325-46a8-9192-66a3b91b1c2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07488486 0.10495135 0.40243965 0.03086603 0.01727828 0.03178379\n",
      "  0.00191605 0.00905633 0.07167643]]\n",
      "[['Intro']]\n",
      "ChatBot: good afternoon\n"
     ]
    }
   ],
   "source": [
    "#Sample string\n",
    "inp='Hello'\n",
    "inp= preprocessInput(inp)\n",
    "result = model_sgd.predict(inp)\n",
    "print(result)\n",
    "tag = ohe.inverse_transform(result)\n",
    "print(tag)\n",
    "for i in ChatBot_corpus['intents']:\n",
    "    #print(i)\n",
    "    if i['tag'] == tag:\n",
    "        print( \"ChatBot:\" ,np.random.choice(i['responses']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "eRMwwnIXULmR"
   },
   "outputs": [],
   "source": [
    "#Defining and initiating the chatbot. The bot will accept inputs from user and provide appropriate resolution until the user inputs 'quit'\n",
    "def chat():\n",
    "  while True:\n",
    "    print(\"User: \" )\n",
    "    inp = input()\n",
    "    if inp.lower() == \"quit\":\n",
    "        break\n",
    "    inp= preprocessInput(inp)\n",
    "    result = model_sgd.predict(inp)\n",
    "    tag = ohe.inverse_transform(result)\n",
    "\n",
    "    for i in ChatBot_corpus['intents']:\n",
    "        if i['tag'] == tag:\n",
    "            print( \"ChatBot:\"  , np.random.choice(i['responses']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "nAJ-UdbjU2F5"
   },
   "outputs": [],
   "source": [
    "def chatWithBot():\n",
    "  print(\"Start messaging with the bot (type quit to stop)!\")\n",
    "  print( \"\\nHi there ! I am your virtual assistant. How may I help you?\")\n",
    "  chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWlhLzvYmyH0",
    "outputId": "cea097fa-7d23-4ca4-b96a-1b876fbac569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n",
      "\n",
      "Hi there ! I am your virtual assistant. How may I help you?\n",
      "User: \n",
      "Hello\n",
      "ChatBot: Hello\n",
      "User: \n",
      "Hi\n",
      "ChatBot: Hello\n",
      "User: \n",
      "How are you\n",
      "ChatBot: Hello\n",
      "User: \n",
      "who are you\n",
      "ChatBot: Any time!\n",
      "User: \n",
      "Help me with machine learning\n",
      "ChatBot: Link: Olympus wiki\n",
      "User: \n",
      "I need help to understand machine learning\n",
      "ChatBot: Link: Machine Learning wiki \n",
      "User: \n",
      "what is a svm\n",
      "ChatBot: Link: Machine Learning wiki \n",
      "User: \n",
      "what is knn model\n",
      "ChatBot: Link: Machine Learning wiki \n",
      "User: \n",
      "what is supervised learning\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "what is neural networks\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "what is deep learning\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "what is meant by SGD\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "what is meant by ANN\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "what do u undertand by epoch\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "explain relu\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "explain CNN\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "what is your name\n",
      "ChatBot: I am your virtual learning assistant\n",
      "User: \n",
      "what are your timings\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "what is your working time\n",
      "ChatBot: Hi\n",
      "User: \n",
      "what are your working hours\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "what are your working hours?\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "what the hell\n",
      "ChatBot: Please use respectful words\n",
      "User: \n",
      "u r a stupid bot\n",
      "ChatBot: I am your virtual learning assistant\n",
      "User: \n",
      "u r stupid\n",
      "ChatBot: Please use respectful words\n",
      "User: \n",
      "u r an idiot\n",
      "ChatBot: Please use respectful words\n",
      "User: \n",
      "my problem is still there\n",
      "ChatBot: good evening\n",
      "User: \n",
      "not resolved\n",
      "ChatBot: Link: Neural Nets wiki\n",
      "User: \n",
      "problem is not solved\n",
      "ChatBot: Tarnsferring the request to your PM\n",
      "User: \n",
      "thank you\n",
      "ChatBot: Any time!\n",
      "User: \n",
      "bye bye\n",
      "ChatBot: Happy to help!\n",
      "User: \n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "chatWithBot(How )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlP_NQeB_hSF"
   },
   "source": [
    "#### Conclusion/Observation:\n",
    "1. There are two types of chatbots that can be designed : \n",
    "Rule based and AI based. Rule based will address and answer queries based on some pre-defined rules.\n",
    "Self learning bots train and learn from the data and provide responses. \n",
    "We have created retrieval based chatbot , a subset of AI/Self learning chatbot, which provides responses based on patterns/intents entered by used. It is usually trained using large quantity of corpus.\n",
    "\n",
    "2. We have created and compared both machine learning and NN models. Using Bag of words vactorization , we have obtained around 35-45% accuracy whereas using NN/DL , we have achieved 73.8% accuracy.\n",
    "3. Although for some of the queries were not correct, chatbot was able to provide appropriate responses using DL model. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ChatbotPython.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
