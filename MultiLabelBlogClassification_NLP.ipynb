{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIQjjxALEmVo"
   },
   "source": [
    "## PART 1: Design a multi-label NLP classifier for blog authorship corpus which will classify blogs based on authors' multiple features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GXM3Lo9FEc2"
   },
   "source": [
    "#### We will import  the corpus, analyse it and split it into text and labels. We will vectorize and compare the text using Bag of Words and TF-IDF vectorization technqiues. We will merge and transform the target classes into binaries. Then we will design , train and tune ML and ANN models and pick which performs best.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coS0WmJzH0xI",
    "outputId": "d3c4b320-c701-4efd-f96e-bb994791c213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "import tensorflow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix,f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,BaggingClassifier\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras import Model,Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout,Input,Embedding,Flatten,BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from tensorflow.keras.initializers import GlorotNormal,GlorotUniform,HeNormal,HeUniform\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,Normalizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKNtqxnsIZ8O",
    "outputId": "c5fdbd8d-2a25-4964-da8c-9bbe7e9dad1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VYBFwJDhIkhN"
   },
   "outputs": [],
   "source": [
    "path ='/content/drive/MyDrive/Great Learning/NLP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GAIqH624QQg"
   },
   "source": [
    "### 1. Import and analyse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UbRxAEcFIokl"
   },
   "outputs": [],
   "source": [
    "blog_csv = pd.read_csv(path + '/blogtext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mej9_1ySI72t",
    "outputId": "93ec38ce-0954-476a-b067-0be9d7bf5e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of blog dataframe :  (681284, 7)\n",
      "Columns of blog dataframe :  Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      681284 non-null  int64 \n",
      " 1   gender  681284 non-null  object\n",
      " 2   age     681284 non-null  int64 \n",
      " 3   topic   681284 non-null  object\n",
      " 4   sign    681284 non-null  object\n",
      " 5   date    681284 non-null  object\n",
      " 6   text    681284 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 36.4+ MB\n",
      "Info of blog dataframe :  None\n"
     ]
    }
   ],
   "source": [
    "#Check for dataset shape, column names and datatypes of columns\n",
    "print(\"Shape of blog dataframe : \", blog_csv.shape)\n",
    "print(\"Columns of blog dataframe : \", blog_csv.columns)\n",
    "print(\"Info of blog dataframe : \", blog_csv.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2Ue-aEhLkgd",
    "outputId": "f908bf12-77e5-4779-db51-df554edf04c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values\n",
    "blog_csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "P6WfBTWUJOQ9",
    "outputId": "ac05cd3f-b98c-47f3-85c8-82c57eba685b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>I had an interesting conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Somehow Coca-Cola has a way of su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>If anything, Korea is a country o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Take a read of this news article ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>I surf the English news sites a l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ...                                               text\n",
       "0  2059027  ...             Info has been found (+/- 100 pages,...\n",
       "1  2059027  ...             These are the team members:   Drewe...\n",
       "2  2059027  ...             In het kader van kernfusie op aarde...\n",
       "3  2059027  ...                   testing!!!  testing!!!          \n",
       "4  3581210  ...               Thanks to Yahoo!'s Toolbar I can ...\n",
       "5  3581210  ...               I had an interesting conversation...\n",
       "6  3581210  ...               Somehow Coca-Cola has a way of su...\n",
       "7  3581210  ...               If anything, Korea is a country o...\n",
       "8  3581210  ...               Take a read of this news article ...\n",
       "9  3581210  ...               I surf the English news sites a l...\n",
       "\n",
       "[10 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "G6nYF_LAJZ3V",
    "outputId": "32689055-eacc-4b17-980e-90d7ff521dbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.812840e+05</td>\n",
       "      <td>681284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.397802e+06</td>\n",
       "      <td>23.932326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.247723e+06</td>\n",
       "      <td>7.786009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.114000e+03</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.239610e+06</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.607577e+06</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.525660e+06</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.337650e+06</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id            age\n",
       "count  6.812840e+05  681284.000000\n",
       "mean   2.397802e+06      23.932326\n",
       "std    1.247723e+06       7.786009\n",
       "min    5.114000e+03      13.000000\n",
       "25%    1.239610e+06      17.000000\n",
       "50%    2.607577e+06      24.000000\n",
       "75%    3.525660e+06      26.000000\n",
       "max    4.337650e+06      48.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 point summary\n",
    "blog_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lf1REo0aJp_d",
    "outputId": "ea1484bd-7405-4958-a44f-fd51e02fc9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unqiue values of column topic are ['Student' 'InvestmentBanking' 'indUnk' 'Non-Profit' 'Banking' 'Education'\n",
      " 'Engineering' 'Science' 'Communications-Media' 'BusinessServices'\n",
      " 'Sports-Recreation' 'Arts' 'Internet' 'Museums-Libraries' 'Accounting'\n",
      " 'Technology' 'Law' 'Consulting' 'Automotive' 'Religion' 'Fashion'\n",
      " 'Publishing' 'Marketing' 'LawEnforcement-Security' 'HumanResources'\n",
      " 'Telecommunications' 'Military' 'Government' 'Transportation'\n",
      " 'Architecture' 'Advertising' 'Agriculture' 'Biotech' 'RealEstate'\n",
      " 'Manufacturing' 'Construction' 'Chemicals' 'Maritime' 'Tourism'\n",
      " 'Environment']\n",
      "Unqiue values of column gender are ['male' 'female']\n",
      "Unqiue values of column sign are ['Leo' 'Aquarius' 'Aries' 'Capricorn' 'Gemini' 'Cancer' 'Sagittarius'\n",
      " 'Scorpio' 'Libra' 'Virgo' 'Taurus' 'Pisces']\n"
     ]
    }
   ],
   "source": [
    "#Check unique column values\n",
    "unique_columns= ['topic','gender','sign']\n",
    "for col in unique_columns:\n",
    "  print(\"Unqiue values of column {} are {}\".format(col,blog_csv[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 978
    },
    "id": "S6rAvuazKXjv",
    "outputId": "08226c44-2078-4919-e13c-e48a2ef2c25d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Count the column values\n",
    "for  col in unique_columns:\n",
    "  sns.countplot(blog_csv[col])\n",
    "  plt.title(col)\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aTry7VNK5YW",
    "outputId": "3d1f8d2d-30f1-4db4-9504-3e51534e8c9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for column topic  is \n",
      " indUnk                     251015\n",
      "Student                    153903\n",
      "Technology                  42055\n",
      "Arts                        32449\n",
      "Education                   29633\n",
      "Communications-Media        20140\n",
      "Internet                    16006\n",
      "Non-Profit                  14700\n",
      "Engineering                 11653\n",
      "Law                          9040\n",
      "Publishing                   7753\n",
      "Science                      7269\n",
      "Government                   6907\n",
      "Consulting                   5862\n",
      "Religion                     5235\n",
      "Fashion                      4851\n",
      "Marketing                    4769\n",
      "Advertising                  4676\n",
      "BusinessServices             4500\n",
      "Banking                      4049\n",
      "Chemicals                    3928\n",
      "Telecommunications           3891\n",
      "Accounting                   3832\n",
      "Military                     3128\n",
      "Museums-Libraries            3096\n",
      "Sports-Recreation            3038\n",
      "HumanResources               3010\n",
      "RealEstate                   2870\n",
      "Transportation               2326\n",
      "Manufacturing                2272\n",
      "Biotech                      2234\n",
      "Tourism                      1942\n",
      "LawEnforcement-Security      1878\n",
      "Architecture                 1638\n",
      "InvestmentBanking            1292\n",
      "Automotive                   1244\n",
      "Agriculture                  1235\n",
      "Construction                 1093\n",
      "Environment                   592\n",
      "Maritime                      280\n",
      "Name: topic, dtype: int64 \n",
      "Count for column gender  is \n",
      " male      345193\n",
      "female    336091\n",
      "Name: gender, dtype: int64 \n",
      "Count for column sign  is \n",
      " Cancer         65048\n",
      "Aries          64979\n",
      "Taurus         62561\n",
      "Libra          62363\n",
      "Virgo          60399\n",
      "Scorpio        57161\n",
      "Pisces         54053\n",
      "Leo            53811\n",
      "Gemini         51985\n",
      "Sagittarius    50036\n",
      "Aquarius       49687\n",
      "Capricorn      49201\n",
      "Name: sign, dtype: int64 \n"
     ]
    }
   ],
   "source": [
    "for col in unique_columns:\n",
    "  print(\"Count for column {}  is \\n {} \".format(col,blog_csv[col].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "w9CFxG53Slgz",
    "outputId": "daacc15b-1887-4b5e-e6ad-a47e3163d27e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2914bb0c50>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "blog_csv.groupby('topic').text.count().plot.bar(ylim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "R3e6v3EFqp0i"
   },
   "outputs": [],
   "source": [
    "#Drop duplicates\n",
    "blog_csv.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNT-Riz5rs-N",
    "outputId": "090e4468-04a6-454d-c0c9-b4b59ee02901"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676598, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape after dropping duplicates\n",
    "blog_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "bQjCyl5816C6",
    "outputId": "a7b05b58-42eb-4f4e-99ab-9106bb4944d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50286</th>\n",
       "      <td>3565077</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>03,August,2004</td>\n",
       "      <td>will be good! i've got a really great f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50287</th>\n",
       "      <td>3565077</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>01,August,2004</td>\n",
       "      <td>just watched it again with my mother, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50288</th>\n",
       "      <td>4263493</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>21,August,2004</td>\n",
       "      <td>Then its time for vacation! w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50289</th>\n",
       "      <td>4263493</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>18,August,2004</td>\n",
       "      <td>I feel like complete and tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50290</th>\n",
       "      <td>4263493</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>17,August,2004</td>\n",
       "      <td>Just a short post to introduc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  ...                                               text\n",
       "0      2059027  ...             Info has been found (+/- 100 pages,...\n",
       "1      2059027  ...             These are the team members:   Drewe...\n",
       "2      2059027  ...             In het kader van kernfusie op aarde...\n",
       "3      2059027  ...                   testing!!!  testing!!!          \n",
       "4      3581210  ...               Thanks to Yahoo!'s Toolbar I can ...\n",
       "...        ...  ...                                                ...\n",
       "50286  3565077  ...         will be good! i've got a really great f...\n",
       "50287  3565077  ...         just watched it again with my mother, a...\n",
       "50288  4263493  ...                   Then its time for vacation! w...\n",
       "50289  4263493  ...                   I feel like complete and tota...\n",
       "50290  4263493  ...                   Just a short post to introduc...\n",
       "\n",
       "[50000 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_csv.iloc[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nom2-YwG1dZZ"
   },
   "outputs": [],
   "source": [
    "# We will work on first 50k records owing to RAM restrictions.\n",
    "blog_test_subrows=blog_csv.iloc[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pt6Iy_W24oXS",
    "outputId": "b2f65cb0-cadf-4327-8742-0bce690c49c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "blog_test_subrows.drop(['id','date'],  axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rAW-E2x4toM",
    "outputId": "e94f4231-9755-4f90-a3c0-672dbb4eddaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'topic', 'sign', 'text'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_test_subrows.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vgWMceSo-o-P",
    "outputId": "a89a9945-8616-4a52-f99f-310b2d9837e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_test_subrows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRSkO-MBAHYR"
   },
   "source": [
    "### 2. Perform pre-processing on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMSLPJZDAQA4"
   },
   "source": [
    "#### 2.1 Remove punctuation marks,special characters, brackets,numbers and characters that are not in English alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTZFZCtjScLO"
   },
   "outputs": [],
   "source": [
    "wnLemm = WordNetLemmatizer()\n",
    "def cleanData(cleanTxt):\n",
    "  cleanTxt=re.sub('[0-9]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[\\'\\\"\\.\\,(){}]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[!@\\*?:;#\\$\\%^&~]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[+-\\/X*]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[\\[\\]=<>]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[<<>>_*]',\" \",cleanTxt)\n",
    "  cleanTxt=re.sub('[^a-zA-Z]',\" \",cleanTxt)\n",
    "  cleanTxt=cleanTxt.lower()\n",
    "  words_token = cleanTxt.split()\n",
    "  words = [wnLemm.lemmatize(word) for word in words_token  if not word  in set(stopwords.words('english'))] \n",
    "  words = \" \".join(words)\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UX-PrECm5iR3",
    "outputId": "363498bd-247a-40b9-adef-96667f0e807c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "blog_test_subrows['text']=blog_test_subrows['text'].apply(cleanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "6RSCJMCM5sfi",
    "outputId": "15f5a2e3-d766-4d54-a4e8-603984e05fc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>info found page mb pdf file wait untill team l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>team member drewes van der laag urllink mail r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>testing testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>thanks yahoo toolbar capture url popups mean s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>urllink doggy bed need say urllink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>ah yes summer olympics halfway settled familia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>current music could magic donna summer feeling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>female</td>\n",
       "      <td>15</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>hey one many thing expression zone hope update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>male</td>\n",
       "      <td>44</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>well today going okay applied job done bill ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  age  ...      sign                                               text\n",
       "0      male   15  ...       Leo  info found page mb pdf file wait untill team l...\n",
       "1      male   15  ...       Leo  team member drewes van der laag urllink mail r...\n",
       "2      male   15  ...       Leo  het kader van kernfusie op aarde maak je eigen...\n",
       "3      male   15  ...       Leo                                    testing testing\n",
       "4      male   33  ...  Aquarius  thanks yahoo toolbar capture url popups mean s...\n",
       "..      ...  ...  ...       ...                                                ...\n",
       "995  female   25  ...    Taurus                 urllink doggy bed need say urllink\n",
       "996  female   25  ...    Taurus  ah yes summer olympics halfway settled familia...\n",
       "997  female   15  ...    Pisces  current music could magic donna summer feeling...\n",
       "998  female   15  ...    Pisces  hey one many thing expression zone hope update...\n",
       "999    male   44  ...    Taurus  well today going okay applied job done bill ba...\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_test_subrows[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlAU_yATAmIy"
   },
   "source": [
    "##### Save the cleaned data to csv so that it can be read and used everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bi0FdBwlQXY6"
   },
   "outputs": [],
   "source": [
    "blog_test_subrows.to_csv(path+'/BlogCsvCleaned_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZE_rKGRS_3dH"
   },
   "outputs": [],
   "source": [
    "blog_test_subrows_new= pd.read_csv(path+'/BlogCsvCleaned_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "zl7VFdtB_8lG",
    "outputId": "81614c79-ee8a-4dc5-aef8-8c80d842959f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>info found page mb pdf file wait untill team l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>team member drewes van der laag urllink mail r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>testing testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>thanks yahoo toolbar capture url popups mean s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>50286</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>good got really great feeling achieve although...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>50287</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>watched mother confirmed love however mum thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>50288</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>time vacation wooo wait day away wonderful wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>50289</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>feel like complete total crap right woke thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>50290</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>short post introduce year old female assistant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  ...                                               text\n",
       "0               0  ...  info found page mb pdf file wait untill team l...\n",
       "1               1  ...  team member drewes van der laag urllink mail r...\n",
       "2               2  ...  het kader van kernfusie op aarde maak je eigen...\n",
       "3               3  ...                                    testing testing\n",
       "4               4  ...  thanks yahoo toolbar capture url popups mean s...\n",
       "...           ...  ...                                                ...\n",
       "49995       50286  ...  good got really great feeling achieve although...\n",
       "49996       50287  ...  watched mother confirmed love however mum thin...\n",
       "49997       50288  ...  time vacation wooo wait day away wonderful wor...\n",
       "49998       50289  ...  feel like complete total crap right woke thing...\n",
       "49999       50290  ...  short post introduce year old female assistant...\n",
       "\n",
       "[50000 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_test_subrows_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk0-VDHSA7xN"
   },
   "source": [
    "#### 2.2 Merge / Transform (Binarize)  target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SLVi6sXOqELl"
   },
   "outputs": [],
   "source": [
    "# We will consider these authors' properties: age, gender, zodiac sign, topic\n",
    "blog_test_subrows_new[\"age\"] = blog_test_subrows_new[\"age\"].astype(str)\n",
    "blog_test_subrows_new[\"labels\"] = blog_test_subrows_new.apply(lambda col :\n",
    "                            [col[\"gender\"],col[\"age\"],col[\"topic\"],col[\"sign\"]],axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cpwV-up0hXkU"
   },
   "outputs": [],
   "source": [
    "blog_test_subrows_new.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "04VKGCeHA_g0"
   },
   "outputs": [],
   "source": [
    "blog_test_subrows_new.drop('Unnamed: 0',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ATfgzYblfGVY"
   },
   "outputs": [],
   "source": [
    "#Split features and category \n",
    "features = blog_test_subrows_new['text']\n",
    "category= blog_test_subrows_new['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Mkjf88siHfUv"
   },
   "outputs": [],
   "source": [
    "#Count the number of entries for each class in all four categories\n",
    "label_counts=dict()\n",
    "\n",
    "for labels in category.values:\n",
    "    for label in labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[str(label)]+=1\n",
    "        else:\n",
    "            label_counts[str(label)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDHU5vbwHh_L",
    "outputId": "5afc6cac-4882-4c25-c0f9-c9f82893cba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys and their counts: \n",
      " {'male': 25535, '15': 3498, 'Student': 10716, 'Leo': 3834, '33': 1641, 'InvestmentBanking': 85, 'Aquarius': 4759, 'female': 24201, '14': 2059, 'indUnk': 17472, 'Aries': 7751, '25': 2822, 'Capricorn': 3801, '17': 6792, 'Gemini': 2583, '23': 5454, 'Non-Profit': 490, 'Cancer': 4494, 'Banking': 273, '37': 306, 'Sagittarius': 4562, '26': 2817, '24': 5748, 'Scorpio': 3194, '27': 4069, 'Education': 2635, '45': 93, 'Engineering': 1396, 'Libra': 4423, 'Science': 688, '34': 1882, '41': 392, 'Communications-Media': 1576, 'BusinessServices': 408, 'Sports-Recreation': 118, 'Virgo': 2808, 'Taurus': 3413, 'Arts': 1838, 'Pisces': 4114, '44': 41, '16': 4166, 'Internet': 1407, 'Museums-Libraries': 285, 'Accounting': 244, '39': 407, '35': 3353, 'Technology': 4336, '36': 1978, 'Law': 307, '46': 328, 'Consulting': 215, 'Automotive': 116, '42': 96, 'Religion': 256, '13': 757, 'Fashion': 1798, '38': 195, '43': 150, 'Publishing': 207, '40': 192, 'Marketing': 408, 'LawEnforcement-Security': 123, 'HumanResources': 79, 'Telecommunications': 12, 'Military': 191, 'Government': 615, 'Transportation': 194, 'Architecture': 67, 'Advertising': 318, '47': 206, 'Agriculture': 78, 'Biotech': 101, 'RealEstate': 17, 'Manufacturing': 441, '48': 294, 'Construction': 28, 'Chemicals': 75, 'Maritime': 54, 'Tourism': 63, 'Environment': 6}\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys and their counts: \\n\",label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wA9dhnBxHkOE",
    "outputId": "d7d1b8d7-9c8e-4730-ccd3-0d829490034f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['13', '14', '15', '16', '17', '23', '24', '25', '26', '27', '33',\n",
       "       '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44',\n",
       "       '45', '46', '47', '48', 'Accounting', 'Advertising', 'Agriculture',\n",
       "       'Aquarius', 'Architecture', 'Aries', 'Arts', 'Automotive',\n",
       "       'Banking', 'Biotech', 'BusinessServices', 'Cancer', 'Capricorn',\n",
       "       'Chemicals', 'Communications-Media', 'Construction', 'Consulting',\n",
       "       'Education', 'Engineering', 'Environment', 'Fashion', 'Gemini',\n",
       "       'Government', 'HumanResources', 'Internet', 'InvestmentBanking',\n",
       "       'Law', 'LawEnforcement-Security', 'Leo', 'Libra', 'Manufacturing',\n",
       "       'Maritime', 'Marketing', 'Military', 'Museums-Libraries',\n",
       "       'Non-Profit', 'Pisces', 'Publishing', 'RealEstate', 'Religion',\n",
       "       'Sagittarius', 'Science', 'Scorpio', 'Sports-Recreation',\n",
       "       'Student', 'Taurus', 'Technology', 'Telecommunications', 'Tourism',\n",
       "       'Transportation', 'Virgo', 'female', 'indUnk', 'male'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the target column into binary format using MultiLabelBinarizer.\n",
    "binarizer=MultiLabelBinarizer(classes=sorted(label_counts.keys()))\n",
    "category = binarizer.fit_transform(category)\n",
    "#Classes in the merged target column\n",
    "binarizer.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROtibIhKH0Mc",
    "outputId": "639570c7-a8fb-4248-96d1-b9b14d728bb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49736, 80)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGDtAMlLBOe9"
   },
   "source": [
    "### 2.3 Vectorize features i.e text column using Bag of words and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BxIS66MmD3Nh"
   },
   "outputs": [],
   "source": [
    "bow=CountVectorizer(ngram_range=(1, 3), max_features=10000)\n",
    "features_bow= bow.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "mKuSTbbygiWc"
   },
   "outputs": [],
   "source": [
    "tdIdf = TfidfVectorizer(ngram_range=(1,2), max_features=20000, stop_words='english',analyzer='word',norm='l2',max_df=0.75)\n",
    "features_idf=tdIdf.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMJ93OQBiyq4",
    "outputId": "7809e633-fe89-4452-d1fb-c032878f49c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49736, 20000)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByO-s-QyH43Z"
   },
   "source": [
    "##### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "D1umQ9tt527A"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "\n",
    "fs=  SelectKBest(chi2, k=2000)\n",
    "features_idf_new =fs.fit_transform(features_idf,category)\n",
    "features_bow_new=fs.fit_transform(features_bow,category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnHR11UuH3ye",
    "outputId": "df9bea3d-e3fb-44aa-8c3c-cd2576680e99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ..., False, False,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaBwW_FeHzyJ",
    "outputId": "0eee0092-9a97-4151-d66c-c6a222cbade0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49736, 2000)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_idf_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtiFg8zBBmt_"
   },
   "source": [
    "#### 2.4 Train and test split into 70:30 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UQINwPDE34Aq"
   },
   "outputs": [],
   "source": [
    "X_train_bow,X_test_bow,y_train_bow,y_test_bow= train_test_split(features_bow,category,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "gsNEMRnDjDTS"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(features_idf_new,category,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "LMWYvme5gp0T"
   },
   "outputs": [],
   "source": [
    "norm=Normalizer()\n",
    "X_train_scale= norm.fit_transform(X_train)\n",
    "X_test_scale=norm.transform(X_test)\n",
    "X_train_bow_scale= norm.fit_transform(X_train_bow)\n",
    "X_test_bow_scale=norm.transform(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3S_vWrSpvDnt",
    "outputId": "fca323c3-6d3c-4eb6-843e-5e320ab8a6be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape : (34815, 2000)\n",
      "X test shape : (14921, 2000)\n",
      "Y train shape : (34815, 80)\n",
      "Y test shape : (14921, 80)\n"
     ]
    }
   ],
   "source": [
    "#Chechking the shapes of split sets\n",
    "print('X train shape :',X_train.shape)\n",
    "print('X test shape :',X_test.shape)\n",
    "print('Y train shape :',y_train.shape)\n",
    "print('Y test shape :',y_test.shape)\n",
    "#print('X valid shape :',X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ygKk1q4CA22"
   },
   "source": [
    "### 3. Design, train, tune and test the best text classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cqrlRZ0CEEJ"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "#### 3.1 Train models without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "TCzsA8gwQOxP"
   },
   "outputs": [],
   "source": [
    "logRegression=LogisticRegression(C=1.0,penalty='l1',solver='liblinear',max_iter =100,multi_class='ovr')\n",
    "multiNomialNB =MultinomialNB()\n",
    "gaussianNB=GaussianNB()\n",
    "svm=SVC(C=1.0,kernel='rbf')\n",
    "decisionCl=DecisionTreeClassifier(criterion='entropy',max_depth=20,max_leaf_nodes=10)\n",
    "randomForest = RandomForestClassifier(n_estimators=15,criterion='entropy',max_depth=20)\n",
    "models={\"logisticRegression \":logRegression,\n",
    "        \"multiNomialNB\":multiNomialNB,\n",
    "        #\"gaussianNB\":gaussianNB,\n",
    "        \"decisionTree\":decisionCl,\"randomForest\":randomForest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoC-LC3qyP5i"
   },
   "outputs": [],
   "source": [
    "#Train using Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rx4_9v58yVVa",
    "outputId": "9556d7bb-743a-47b7-8637-1a4b150c9bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====KNN prediction using Bag of Words vectorization====\n",
      "Accuracy :  0.028885463440788153\n",
      "F1_score : \n",
      " 0.05275387693510043\n",
      "F1_score : \n",
      " 0.22756897395605244\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=10,algorithm='auto',weights=\"uniform\")\n",
    "knn.fit(X_train_bow_scale,y_train_bow)\n",
    "pred_i = knn.predict(X_test_bow_scale)\n",
    "print(\"=====KNN prediction using Bag of Words vectorization====\")\n",
    "print(\"Accuracy : \",accuracy_score(y_test_bow,pred_i))\n",
    "print(\"F1_score : \\n\",f1_score(y_test_bow,pred_i,average='macro'))\n",
    "print(\"F1_score : \\n\",f1_score(y_test_bow,pred_i,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-whwVg-6eeMQ",
    "outputId": "00314188-e86d-48c6-dc9d-9972f99eb302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Prediction using Bag of words as vectorization method========\n",
      "logisticRegression \n",
      "\n",
      "Accuracy score for training set for model logisticRegression  is 0.12635358322562115\n",
      "\n",
      "Accuracy score for testing set for model logisticRegression  is 0.11520675557938476\n",
      "\n",
      "F1 score :\n",
      " 0.19383165909074246\n",
      "multiNomialNB\n",
      "\n",
      "Accuracy score for training set for model multiNomialNB is 0.03518598305328163\n",
      "\n",
      "Accuracy score for testing set for model multiNomialNB is 0.03062797399638094\n",
      "\n",
      "F1 score :\n",
      " 0.05470074651607484\n",
      "decisionTree\n",
      "\n",
      "Accuracy score for training set for model decisionTree is 0.06709751543874766\n",
      "\n",
      "Accuracy score for testing set for model decisionTree is 0.06420481200991891\n",
      "\n",
      "F1 score :\n",
      " 0.22235947517916027\n",
      "randomForest\n",
      "\n",
      "Accuracy score for training set for model randomForest is 0.037311503662214564\n",
      "\n",
      "Accuracy score for testing set for model randomForest is 0.023523892500502647\n",
      "\n",
      "F1 score :\n",
      " 0.054391421594737574\n"
     ]
    }
   ],
   "source": [
    "#OneVsRestClassifier is used in case of multi label classification. This will try to fit one class versus all other classes in the column.\n",
    "accuracy_score_test =[]\n",
    "accuracy_score_train =[]\n",
    "print(\"=============Prediction using Bag of words as vectorization method========\")\n",
    "for model,objct in models.items():\n",
    "    print(model)\n",
    "    objct=OneVsRestClassifier(objct)\n",
    "    objct.fit(X_train_bow_scale,y_train_bow)\n",
    "    model_predict = objct.predict(X_test_bow_scale)\n",
    "    model_predict_train=objct.predict(X_train_bow_scale)\n",
    "    #accuracy_score_train.append(accuracy_score(y_train,model_predict_train))\n",
    "   # accuracy_score_test.append(accuracy_score(y_ros,model_predict))\n",
    "    \n",
    "    print(\"Accuracy score for training set for model {} is {}\".format(model, accuracy_score(y_train_bow,model_predict_train)))\n",
    "    print(\"Accuracy score for testing set for model {} is {}\".format(model, accuracy_score(y_test_bow,model_predict)))   \n",
    "    print(\"F1 score :\\n\",f1_score(y_test_bow,model_predict,average='macro'))\n",
    "    #print out the classification report\n",
    "    #print(\"Classification report:\\n\",classification_report(y_test,model_predict))\n",
    "    #print(pd.Series(model_predict).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSDdSVksya1l"
   },
   "outputs": [],
   "source": [
    "#Train with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsphTGZgr-NP",
    "outputId": "2c869bea-2c72-4819-8d74-6d25ff2707e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Prediction using TF-IDF as vectorization method========\n",
      "logisticRegression \n",
      "\n",
      "Accuracy score for training set for model logisticRegression  is 0.18572454401838287\n",
      "\n",
      "Accuracy score for testing set for model logisticRegression  is 0.17411701628577173\n",
      "\n",
      "F1 score :\n",
      " 0.2829554910807929\n",
      "multiNomialNB\n",
      "\n",
      "Accuracy score for training set for model multiNomialNB is 0.11141749246014648\n",
      "\n",
      "Accuracy score for testing set for model multiNomialNB is 0.10709737953220294\n",
      "\n",
      "F1 score :\n",
      " 0.1412103963878209\n",
      "decisionTree\n",
      "\n",
      "Accuracy score for training set for model decisionTree is 0.0682751687491024\n",
      "\n",
      "Accuracy score for testing set for model decisionTree is 0.06675155820655453\n",
      "\n",
      "F1 score :\n",
      " 0.25778176523885354\n",
      "randomForest\n",
      "\n",
      "Accuracy score for training set for model randomForest is 0.06635071090047394\n",
      "\n",
      "Accuracy score for testing set for model randomForest is 0.04925943301387307\n",
      "\n",
      "F1 score :\n",
      " 0.11475728378787924\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_test =[]\n",
    "accuracy_score_train =[]\n",
    "print(\"\\n=============Prediction using TF-IDF as vectorization method========\")\n",
    "for model,objct in models.items():\n",
    "    print(model)\n",
    "    objct=OneVsRestClassifier(objct)\n",
    "    objct.fit(X_train_scale,y_train)\n",
    "    model_predict = objct.predict(X_test_scale)\n",
    "    model_predict_train=objct.predict(X_train_scale)\n",
    "    #accuracy_score_train.append(accuracy_score(y_train,model_predict_train))\n",
    "   # accuracy_score_test.append(accuracy_score(y_ros,model_predict))\n",
    "    print(\"\\nAccuracy score for training set for model {} is {}\".format(model, accuracy_score(y_train,model_predict_train)))\n",
    "    print(\"\\nAccuracy score for testing set for model {} is {}\".format(model, accuracy_score(y_test,model_predict)))   \n",
    "    print(\"\\nF1 score :\\n\",f1_score(y_test,model_predict,average='macro'))\n",
    "    #print out the classification report\n",
    "    #print(\"Classification report:\\n\",classification_report(y_test,model_predict))\n",
    "    #print(pd.Series(model_predict).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uf0cDGqRu-72",
    "outputId": "c99839f3-f076-40b2-efd2-30bc81202438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "error_rate=[]\n",
    "for i in range(1,25,2):\n",
    "  print(i)\n",
    "  knn=KNeighborsClassifier(n_neighbors=i)\n",
    "  knn.fit(X_train,y_train)\n",
    "  pred_i = knn.predict(X_test)\n",
    "  error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "5uvsCaLxvDnk",
    "outputId": "f7b2f157-add1-41a6-f045-ff7d3beed33c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,25,2),error_rate,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6uLYGfyu258",
    "outputId": "5ba864ef-317a-44e2-855c-e0d68519cd7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====KNN prediction using TD-IDF vectorization====\n",
      "Accuracy :  0.10582400643388513\n",
      "F1_score : \n",
      " 0.15440935551987559\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=10,algorithm='auto',weights=\"uniform\")\n",
    "knn.fit(X_train_scale,y_train)\n",
    "pred_i = knn.predict(X_test_scale)\n",
    "print(\"=====KNN prediction using TD-IDF vectorization====\")\n",
    "print(\"Accuracy : \",accuracy_score(y_test,pred_i))\n",
    "print(\"F1_score : \\n\",f1_score(y_test,pred_i,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSoFMPshCgIS"
   },
   "source": [
    "#### 3.2 Train and tune with hyperparamater tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KAMCQHeuxnp"
   },
   "outputs": [],
   "source": [
    "#With hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "yyfEKhVKQ7Rg"
   },
   "outputs": [],
   "source": [
    "#param grid \n",
    "param_grid_lr = {'estimator__C':list(range(1,3)),\n",
    "                'estimator__penalty': ['l1'],\n",
    "                 'estimator__solver':  ['liblinear','saga'],\n",
    "                 \n",
    "                }\n",
    "param_grid_nb = {'estimator__alpha': list(range(1,10))}\n",
    "\n",
    "param_grid_knn = {'estimator__n_neighbors': list(range(1,20)),\n",
    "             'estimator__algorithm': ['auto', 'brute'],\n",
    "             'estimator__weights':['uniform','distance']}\n",
    "\n",
    "\n",
    "\n",
    "param_grid_decisionCl = {'estimator__criterion':['gini','entropy'],\n",
    "                         'estimator__splitter':['best','random'],\n",
    "                         'estimator__max_depth':list(range(2,10)),\n",
    "                         'estimator__max_leaf_nodes':list(range(2,10))\n",
    "                        }\n",
    "\n",
    "param_grid_rf ={'estimator__n_estimators':list(range(1,100)),'estimator__criterion':['gini','entropy'],'estimator__max_depth':list(range(1,100))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ywfcOiH3tr7Q"
   },
   "outputs": [],
   "source": [
    "rs_lr=  RandomizedSearchCV(OneVsRestClassifier(LogisticRegression(max_iter=1)),param_grid_lr,n_iter=1,cv=2)\n",
    "rs_knn =RandomizedSearchCV(OneVsRestClassifier(KNeighborsClassifier()),param_grid_knn,n_iter=5,cv=5)\n",
    "rs_nb= RandomizedSearchCV(OneVsRestClassifier(multiNomialNB),param_grid_nb,n_iter=10,cv=5)\n",
    "rs_dcl = RandomizedSearchCV(OneVsRestClassifier(decisionCl),param_grid_decisionCl,n_iter=5,cv=5,verbose=2)\n",
    "rs_rf = RandomizedSearchCV(OneVsRestClassifier(randomForest),param_grid_rf,n_iter=5,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "tp4tEE0MQ_QD"
   },
   "outputs": [],
   "source": [
    "grids = [rs_rf]\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0:'DecisionTreeClassifier',1:'RandomForest',2:'Naive Bayes',3:'Logistic Regression'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-L26ODJ6DgiI"
   },
   "outputs": [],
   "source": [
    "#Preditct using TF-IDF as vectorization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXoPIAu6D4An",
    "outputId": "8fc3470c-679d-4291-957e-ecc31dd346da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Prediction using TF-IDF as vectorization method for logistic Regression========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'estimator__solver': 'saga', 'estimator__penalty': 'l1', 'estimator__C': 2}\n",
      "Test set accuracy score for best params: 0.154 \n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.18      0.30       218\n",
      "           1       0.81      0.17      0.29       646\n",
      "           2       0.73      0.23      0.35      1041\n",
      "           3       0.85      0.21      0.34      1219\n",
      "           4       0.80      0.28      0.41      2062\n",
      "           5       0.76      0.20      0.31      1650\n",
      "           6       0.75      0.28      0.41      1693\n",
      "           7       0.75      0.07      0.13       864\n",
      "           8       0.88      0.10      0.18       805\n",
      "           9       0.77      0.19      0.30      1196\n",
      "          10       0.57      0.12      0.20       514\n",
      "          11       0.95      0.59      0.72       563\n",
      "          12       0.60      0.34      0.43      1031\n",
      "          13       0.93      0.44      0.60       620\n",
      "          14       0.83      0.05      0.10        93\n",
      "          15       0.67      0.07      0.12        60\n",
      "          16       0.83      0.15      0.25       101\n",
      "          17       0.44      0.12      0.19        56\n",
      "          18       0.79      0.23      0.36       116\n",
      "          19       0.00      0.00      0.00        32\n",
      "          20       1.00      0.11      0.20        36\n",
      "          21       0.00      0.00      0.00        13\n",
      "          22       1.00      0.10      0.19        29\n",
      "          23       1.00      0.06      0.12       114\n",
      "          24       1.00      0.10      0.18        60\n",
      "          25       1.00      0.19      0.32        89\n",
      "          26       0.00      0.00      0.00        69\n",
      "          27       0.88      0.49      0.63        76\n",
      "          28       0.00      0.00      0.00        31\n",
      "          29       0.80      0.30      0.44      1418\n",
      "          30       0.00      0.00      0.00        21\n",
      "          31       0.70      0.33      0.45      2346\n",
      "          32       0.70      0.11      0.19       564\n",
      "          33       0.80      0.11      0.19        37\n",
      "          34       0.90      0.12      0.20        78\n",
      "          35       1.00      0.03      0.07        29\n",
      "          36       0.91      0.19      0.32       109\n",
      "          37       0.72      0.19      0.30      1369\n",
      "          38       0.80      0.32      0.46      1116\n",
      "          39       1.00      0.04      0.07        26\n",
      "          40       0.64      0.08      0.13       465\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       1.00      0.07      0.12        61\n",
      "          43       0.83      0.37      0.51       769\n",
      "          44       0.84      0.35      0.50       423\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.88      0.49      0.63       577\n",
      "          47       0.85      0.12      0.21       774\n",
      "          48       0.74      0.12      0.21       165\n",
      "          49       1.00      0.15      0.26        27\n",
      "          50       0.71      0.11      0.18       435\n",
      "          51       0.79      0.55      0.65        20\n",
      "          52       1.00      0.07      0.13       102\n",
      "          53       1.00      0.03      0.06        34\n",
      "          54       0.78      0.12      0.20      1162\n",
      "          55       0.81      0.31      0.45      1299\n",
      "          56       0.94      0.22      0.36       134\n",
      "          57       0.00      0.00      0.00        14\n",
      "          58       0.91      0.18      0.30       117\n",
      "          59       0.89      0.26      0.41        61\n",
      "          60       1.00      0.60      0.75        87\n",
      "          61       0.80      0.03      0.05       157\n",
      "          62       0.79      0.24      0.37      1224\n",
      "          63       1.00      0.04      0.09        67\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.45      0.16      0.23        83\n",
      "          66       0.90      0.24      0.37      1403\n",
      "          67       0.92      0.22      0.35       213\n",
      "          68       0.71      0.13      0.22       965\n",
      "          69       0.00      0.00      0.00        34\n",
      "          70       0.78      0.29      0.42      3223\n",
      "          71       0.63      0.08      0.14      1026\n",
      "          72       0.70      0.22      0.33      1289\n",
      "          73       0.00      0.00      0.00         4\n",
      "          74       0.00      0.00      0.00        20\n",
      "          75       1.00      0.03      0.06        61\n",
      "          76       0.63      0.08      0.14       819\n",
      "          77       0.69      0.69      0.69      7290\n",
      "          78       0.75      0.31      0.44      5223\n",
      "          79       0.78      0.56      0.65      7631\n",
      "\n",
      "   micro avg       0.75      0.34      0.47     59684\n",
      "   macro avg       0.70      0.18      0.26     59684\n",
      "weighted avg       0.76      0.34      0.44     59684\n",
      " samples avg       0.60      0.34      0.40     59684\n",
      "\n",
      "F1 score :\n",
      " 0.43514213339008284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=============Prediction using TF-IDF as vectorization method for logistic Regression========\")\n",
    "\n",
    "rs_lr.fit(X_train_scale, y_train)\n",
    "# Best params\n",
    "print('Best params: %s' % rs_lr.best_params_)\n",
    "# Predict on test data with best params\n",
    "y_pred = rs_lr.predict(X_test_scale)\n",
    "# Test data accuracy of model with best params\n",
    "print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "print('Classification report:\\n',classification_report(y_test,y_pred))\n",
    "print(\"F1 score :\\n\",f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9-QNLoh1Wc9",
    "outputId": "ae97b08e-0c99-4ebc-d3fa-38dc5c2b513c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Prediction using TF-IDF vectorization method for RandomForest========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=============Prediction using TF-IDF vectorization method for RandomForest========\")\n",
    "scores_rf= cross_val_score(randomForest, X_train_scale, y_train,  cv=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKtexXrB2ZdN",
    "outputId": "a5d71ba0-be48-4995-ea87-30e0f10f885a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030303030303030304\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_y7AlItD7rj",
    "outputId": "943fb5ee-8dcb-4112-9901-05c3b659f69b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Prediction using TF-IDF as vectorization method for Naive Bayes========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'estimator__alpha': 1}\n",
      "Test set accuracy score for best params: 0.107 \n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.06      0.10       218\n",
      "           1       0.58      0.11      0.18       646\n",
      "           2       0.73      0.15      0.25      1041\n",
      "           3       0.81      0.17      0.29      1219\n",
      "           4       0.91      0.22      0.36      2062\n",
      "           5       0.83      0.13      0.22      1650\n",
      "           6       0.86      0.15      0.25      1693\n",
      "           7       0.66      0.04      0.07       864\n",
      "           8       0.70      0.06      0.12       805\n",
      "           9       0.96      0.09      0.17      1196\n",
      "          10       0.27      0.01      0.03       514\n",
      "          11       0.85      0.41      0.56       563\n",
      "          12       0.70      0.16      0.27      1031\n",
      "          13       0.91      0.32      0.47       620\n",
      "          14       0.00      0.00      0.00        93\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       0.20      0.05      0.08       101\n",
      "          17       0.00      0.00      0.00        56\n",
      "          18       0.36      0.15      0.21       116\n",
      "          19       0.00      0.00      0.00        32\n",
      "          20       0.00      0.00      0.00        36\n",
      "          21       0.00      0.00      0.00        13\n",
      "          22       0.00      0.00      0.00        29\n",
      "          23       0.05      0.01      0.01       114\n",
      "          24       0.21      0.13      0.16        60\n",
      "          25       0.10      0.02      0.04        89\n",
      "          26       0.00      0.00      0.00        69\n",
      "          27       0.69      0.29      0.41        76\n",
      "          28       0.00      0.00      0.00        31\n",
      "          29       0.87      0.20      0.32      1418\n",
      "          30       0.00      0.00      0.00        21\n",
      "          31       0.94      0.20      0.33      2346\n",
      "          32       0.50      0.03      0.05       564\n",
      "          33       0.00      0.00      0.00        37\n",
      "          34       0.10      0.03      0.04        78\n",
      "          35       0.00      0.00      0.00        29\n",
      "          36       0.00      0.00      0.00       109\n",
      "          37       0.91      0.10      0.19      1369\n",
      "          38       0.93      0.20      0.33      1116\n",
      "          39       0.00      0.00      0.00        26\n",
      "          40       0.08      0.00      0.01       465\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.10      0.03      0.05        61\n",
      "          43       0.75      0.31      0.44       769\n",
      "          44       0.71      0.11      0.19       423\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.91      0.34      0.49       577\n",
      "          47       0.78      0.07      0.13       774\n",
      "          48       0.20      0.03      0.05       165\n",
      "          49       0.00      0.00      0.00        27\n",
      "          50       0.20      0.01      0.02       435\n",
      "          51       0.00      0.00      0.00        20\n",
      "          52       0.05      0.01      0.02       102\n",
      "          53       0.00      0.00      0.00        34\n",
      "          54       0.73      0.05      0.10      1162\n",
      "          55       0.96      0.18      0.30      1299\n",
      "          56       0.17      0.03      0.05       134\n",
      "          57       0.00      0.00      0.00        14\n",
      "          58       0.10      0.02      0.03       117\n",
      "          59       0.00      0.00      0.00        61\n",
      "          60       0.61      0.34      0.44        87\n",
      "          61       0.00      0.00      0.00       157\n",
      "          62       0.87      0.19      0.31      1224\n",
      "          63       0.00      0.00      0.00        67\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.00      0.00      0.00        83\n",
      "          66       0.96      0.17      0.29      1403\n",
      "          67       0.58      0.12      0.20       213\n",
      "          68       0.71      0.06      0.10       965\n",
      "          69       0.00      0.00      0.00        34\n",
      "          70       0.79      0.26      0.39      3223\n",
      "          71       0.57      0.04      0.08      1026\n",
      "          72       0.67      0.14      0.23      1289\n",
      "          73       0.00      0.00      0.00         4\n",
      "          74       0.00      0.00      0.00        20\n",
      "          75       0.00      0.00      0.00        61\n",
      "          76       0.47      0.02      0.05       819\n",
      "          77       0.70      0.73      0.71      7290\n",
      "          78       0.84      0.26      0.40      5223\n",
      "          79       0.73      0.70      0.71      7631\n",
      "\n",
      "   micro avg       0.73      0.30      0.42     59684\n",
      "   macro avg       0.38      0.10      0.14     59684\n",
      "weighted avg       0.74      0.30      0.37     59684\n",
      " samples avg       0.70      0.30      0.39     59684\n",
      "\n",
      "F1 score :\n",
      " 0.3720918755314902\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=============Prediction using TF-IDF as vectorization method for Naive Bayes========\")\n",
    "\n",
    "rs_nb.fit(X_train_scale, y_train)\n",
    "# Best params\n",
    "print('Best params: %s' % rs_nb.best_params_)\n",
    "# Predict on test data with best params\n",
    "y_pred = rs_nb.predict(X_test_scale)\n",
    "# Test data accuracy of model with best params\n",
    "print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "print('Classification report:\\n',classification_report(y_test,y_pred))\n",
    "print(\"F1 score :\\n\",f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9igu1of0tBq",
    "outputId": "a6690387-b57e-4eca-f71a-6c9d3d87009b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Prediction using Bag of words as vectorization method for TandomForest========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.5min finished\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=============Prediction using Bag of words as vectorization method for TandomForest========\")\n",
    "scores_rf= cross_val_score(randomForest, X_train_bow_scale, y_train_bow,  cv=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34MsNrtw1092",
    "outputId": "df64570e-dbe1-47cb-e309-0233de770d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02208818038201924\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieiSyBItHSRp",
    "outputId": "c24bc8b2-7574-4678-cb33-c721a029db2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Prediction using Bag of words as vectorization method for logistic Regression========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'estimator__solver': 'liblinear', 'estimator__penalty': 'l1', 'estimator__C': 2}\n",
      "Test set accuracy score for best params: 0.058 \n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.17      0.10       218\n",
      "           1       0.19      0.18      0.19       646\n",
      "           2       0.28      0.23      0.25      1041\n",
      "           3       0.36      0.23      0.28      1219\n",
      "           4       0.47      0.31      0.37      2062\n",
      "           5       0.61      0.18      0.28      1650\n",
      "           6       0.44      0.30      0.36      1693\n",
      "           7       0.11      0.09      0.10       864\n",
      "           8       0.13      0.11      0.12       805\n",
      "           9       0.27      0.19      0.23      1196\n",
      "          10       0.07      0.08      0.07       514\n",
      "          11       0.35      0.51      0.42       563\n",
      "          12       0.35      0.29      0.32      1031\n",
      "          13       0.35      0.35      0.35       620\n",
      "          14       0.02      0.08      0.03        93\n",
      "          15       0.01      0.03      0.01        60\n",
      "          16       0.06      0.26      0.10       101\n",
      "          17       0.02      0.12      0.03        56\n",
      "          18       0.06      0.22      0.09       116\n",
      "          19       0.00      0.00      0.00        32\n",
      "          20       0.00      0.06      0.01        36\n",
      "          21       0.00      0.08      0.00        13\n",
      "          22       0.01      0.24      0.03        29\n",
      "          23       0.02      0.07      0.03       114\n",
      "          24       0.01      0.10      0.02        60\n",
      "          25       0.03      0.11      0.05        89\n",
      "          26       0.01      0.04      0.01        69\n",
      "          27       0.07      0.45      0.13        76\n",
      "          28       0.00      0.00      0.00        31\n",
      "          29       0.35      0.29      0.32      1418\n",
      "          30       0.00      0.00      0.00        21\n",
      "          31       0.54      0.34      0.42      2346\n",
      "          32       0.09      0.11      0.10       564\n",
      "          33       0.01      0.14      0.02        37\n",
      "          34       0.01      0.08      0.02        78\n",
      "          35       0.00      0.00      0.00        29\n",
      "          36       0.03      0.13      0.05       109\n",
      "          37       0.30      0.17      0.22      1369\n",
      "          38       0.32      0.24      0.28      1116\n",
      "          39       0.00      0.08      0.01        26\n",
      "          40       0.06      0.09      0.07       465\n",
      "          41       0.00      0.14      0.01         7\n",
      "          42       0.01      0.07      0.01        61\n",
      "          43       0.31      0.36      0.33       769\n",
      "          44       0.17      0.28      0.22       423\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.33      0.43      0.38       577\n",
      "          47       0.17      0.14      0.15       774\n",
      "          48       0.05      0.15      0.08       165\n",
      "          49       0.01      0.22      0.02        27\n",
      "          50       0.12      0.15      0.14       435\n",
      "          51       0.01      0.20      0.02        20\n",
      "          52       0.01      0.05      0.02       102\n",
      "          53       0.00      0.00      0.00        34\n",
      "          54       0.23      0.13      0.17      1162\n",
      "          55       0.36      0.31      0.33      1299\n",
      "          56       0.06      0.20      0.09       134\n",
      "          57       0.00      0.00      0.00        14\n",
      "          58       0.04      0.18      0.07       117\n",
      "          59       0.02      0.16      0.04        61\n",
      "          60       0.09      0.48      0.15        87\n",
      "          61       0.02      0.05      0.03       157\n",
      "          62       0.32      0.25      0.28      1224\n",
      "          63       0.00      0.03      0.01        67\n",
      "          64       0.00      0.17      0.00         6\n",
      "          65       0.57      0.05      0.09        83\n",
      "          66       0.34      0.25      0.29      1403\n",
      "          67       0.06      0.12      0.08       213\n",
      "          68       0.14      0.10      0.12       965\n",
      "          69       0.00      0.03      0.00        34\n",
      "          70       0.54      0.37      0.43      3223\n",
      "          71       0.21      0.13      0.16      1026\n",
      "          72       0.35      0.29      0.32      1289\n",
      "          73       0.00      0.00      0.00         4\n",
      "          74       0.00      0.00      0.00        20\n",
      "          75       0.00      0.02      0.00        61\n",
      "          76       0.14      0.10      0.11       819\n",
      "          77       0.70      0.71      0.71      7290\n",
      "          78       0.59      0.45      0.51      5223\n",
      "          79       0.73      0.70      0.72      7631\n",
      "\n",
      "   micro avg       0.34      0.37      0.36     59684\n",
      "   macro avg       0.16      0.18      0.14     59684\n",
      "weighted avg       0.44      0.37      0.40     59684\n",
      " samples avg       0.48      0.37      0.38     59684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :\n",
      " 0.39691814921022145\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=============Prediction using Bag of words as vectorization method for logistic Regression========\")\n",
    "\n",
    "rs_lr.fit(X_train_bow_scale, y_train_bow)\n",
    "# Best params\n",
    "print('Best params: %s' % rs_lr.best_params_)\n",
    "# Predict on test data with best params\n",
    "y_pred = rs_lr.predict(X_test_bow_scale)\n",
    "# Test data accuracy of model with best params\n",
    "print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test_bow, y_pred))\n",
    "print('Classification report:\\n',classification_report(y_test_bow,y_pred))\n",
    "print(\"F1 score :\\n\",f1_score(y_test_bow,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFk8OZFsEBgz",
    "outputId": "538612ee-eef6-4f05-fd0d-f8e5a79fd8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Prediction using Bag of words as vectorization method for Naive Bayes========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'estimator__alpha': 1}\n",
      "Test set accuracy score for best params: 0.031 \n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       218\n",
      "           1       0.85      0.02      0.03       646\n",
      "           2       0.87      0.04      0.08      1041\n",
      "           3       0.92      0.06      0.11      1219\n",
      "           4       0.90      0.03      0.06      2062\n",
      "           5       0.70      0.04      0.07      1650\n",
      "           6       0.90      0.07      0.12      1693\n",
      "           7       0.00      0.00      0.00       864\n",
      "           8       0.73      0.02      0.04       805\n",
      "           9       0.00      0.00      0.00      1196\n",
      "          10       0.00      0.00      0.00       514\n",
      "          11       0.87      0.29      0.43       563\n",
      "          12       0.53      0.02      0.03      1031\n",
      "          13       0.96      0.04      0.07       620\n",
      "          14       0.00      0.00      0.00        93\n",
      "          15       0.00      0.00      0.00        60\n",
      "          16       1.00      0.01      0.02       101\n",
      "          17       0.00      0.00      0.00        56\n",
      "          18       0.00      0.00      0.00       116\n",
      "          19       0.00      0.00      0.00        32\n",
      "          20       0.00      0.00      0.00        36\n",
      "          21       0.00      0.00      0.00        13\n",
      "          22       0.00      0.00      0.00        29\n",
      "          23       0.00      0.00      0.00       114\n",
      "          24       0.00      0.00      0.00        60\n",
      "          25       0.00      0.00      0.00        89\n",
      "          26       0.00      0.00      0.00        69\n",
      "          27       0.78      0.18      0.30        76\n",
      "          28       0.00      0.00      0.00        31\n",
      "          29       0.89      0.12      0.21      1418\n",
      "          30       0.00      0.00      0.00        21\n",
      "          31       0.95      0.08      0.15      2346\n",
      "          32       0.00      0.00      0.00       564\n",
      "          33       0.00      0.00      0.00        37\n",
      "          34       0.00      0.00      0.00        78\n",
      "          35       0.00      0.00      0.00        29\n",
      "          36       0.00      0.00      0.00       109\n",
      "          37       0.91      0.04      0.08      1369\n",
      "          38       0.90      0.01      0.02      1116\n",
      "          39       0.00      0.00      0.00        26\n",
      "          40       0.00      0.00      0.00       465\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.00      0.00      0.00        61\n",
      "          43       0.78      0.23      0.35       769\n",
      "          44       0.00      0.00      0.00       423\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.95      0.03      0.07       577\n",
      "          47       0.96      0.03      0.07       774\n",
      "          48       0.00      0.00      0.00       165\n",
      "          49       0.00      0.00      0.00        27\n",
      "          50       0.00      0.00      0.00       435\n",
      "          51       0.00      0.00      0.00        20\n",
      "          52       0.00      0.00      0.00       102\n",
      "          53       0.00      0.00      0.00        34\n",
      "          54       0.75      0.00      0.01      1162\n",
      "          55       0.90      0.01      0.03      1299\n",
      "          56       0.00      0.00      0.00       134\n",
      "          57       0.00      0.00      0.00        14\n",
      "          58       0.00      0.00      0.00       117\n",
      "          59       0.00      0.00      0.00        61\n",
      "          60       0.00      0.00      0.00        87\n",
      "          61       0.00      0.00      0.00       157\n",
      "          62       0.84      0.06      0.12      1224\n",
      "          63       0.00      0.00      0.00        67\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.00      0.00      0.00        83\n",
      "          66       0.93      0.01      0.02      1403\n",
      "          67       0.25      0.00      0.01       213\n",
      "          68       0.00      0.00      0.00       965\n",
      "          69       0.00      0.00      0.00        34\n",
      "          70       0.81      0.14      0.24      3223\n",
      "          71       0.41      0.01      0.02      1026\n",
      "          72       0.46      0.02      0.05      1289\n",
      "          73       0.00      0.00      0.00         4\n",
      "          74       0.00      0.00      0.00        20\n",
      "          75       0.00      0.00      0.00        61\n",
      "          76       0.00      0.00      0.00       819\n",
      "          77       0.68      0.72      0.70      7290\n",
      "          78       0.91      0.10      0.17      5223\n",
      "          79       0.72      0.68      0.70      7631\n",
      "\n",
      "   micro avg       0.72      0.21      0.33     59684\n",
      "   macro avg       0.30      0.04      0.05     59684\n",
      "weighted avg       0.68      0.21      0.25     59684\n",
      " samples avg       0.70      0.21      0.31     59684\n",
      "\n",
      "F1 score :\n",
      " 0.24502552211765471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=============Prediction using Bag of words as vectorization method for Naive Bayes========\")\n",
    "\n",
    "rs_nb.fit(X_train_bow_scale, y_train_bow)\n",
    "# Best params\n",
    "print('Best params: %s' % rs_nb.best_params_)\n",
    "# Predict on test data with best params\n",
    "y_pred = rs_nb.predict(X_test_bow_scale)\n",
    "# Test data accuracy of model with best params\n",
    "print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test_bow, y_pred))\n",
    "print('Classification report:\\n',classification_report(y_test_bow,y_pred))\n",
    "print(\"F1 score :\\n\",f1_score(y_test_bow,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8qn_wFAqsJJ"
   },
   "source": [
    "#### Train and tune a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "VjcpY3myLno9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "embedding_dim = 2000\n",
    "max_len = 200\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(features)\n",
    "sequences = tokenizer.texts_to_sequences(features)\n",
    "X_feat_seq = pad_sequences(sequences, truncating='post', maxlen=max_len)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbqEaPZXKmlZ",
    "outputId": "2f563b02-e42d-45e4-888f-f066ad4be5a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "\n",
    "f = open('/content/drive/MyDrive/Great Learning/NLP/glove.6B.50d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "# create a weight matrix for words in training docs\n",
    "\n",
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "3pY7lKhMK5n3"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 50))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "y936xyvZJMQy"
   },
   "outputs": [],
   "source": [
    "X_trainNN,X_testNN,y_trainNN,y_testNN=train_test_split(X_feat_seq,category,random_state=42,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "04WrgQvMLHT9"
   },
   "outputs": [],
   "source": [
    "def train_test_model(Lambda,lr,epoch):\n",
    "  modelNN=Sequential()\n",
    "  modelNN.add(Input(shape=(max_len) ))\n",
    "\n",
    "  modelNN.add(Embedding(vocab_size,50,weights=[embedding_matrix],input_length=max_len))\n",
    "  modelNN.add(Flatten())\n",
    "  #modelNN.add(Dense(512,activation='relu',kernel_initializer=GlorotNormal()))\n",
    "  modelNN.add(BatchNormalization())\n",
    "  modelNN.add(Dropout(0.2))\n",
    "  #modelNN.add(Dense(256,activation='relu',kernel_initializer=GlorotNormal()))\n",
    "  #m#odelNN.add(BatchNormalization())\n",
    "  #modelNN.add(Dropout(0.2))\n",
    "  #modelNN.add(Dense(256,activation='relu',kernel_initializer=GlorotNormal()))\n",
    "  #modelNN.add(BatchNormalization())\n",
    "  #modelNN.add(Dropout(0.2))\n",
    "  #modelNN.add(Dense(128,activation='relu',kernel_initializer=GlorotNormal()))\n",
    "  #modelNN.add(BatchNormalization())\n",
    "  #modelNN.add(Dropout(0.2))\n",
    "  modelNN.add(Dense(80,activation='sigmoid',kernel_initializer=GlorotNormal()))\n",
    "  sgd=tensorflow.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "  modelNN.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "  history = modelNN.fit(X_trainNN, y_trainNN, batch_size=100, epochs=epoch, verbose=1,validation_split=0.2)\n",
    "  acc=modelNN.evaluate(X_testNN,y_testNN)\n",
    "  return acc,modelNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYTYeHJ8x7Hm",
    "outputId": "c2d0b01f-2b8b-43ba-970f-d265eb7eefae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "279/279 [==============================] - 16s 56ms/step - loss: 0.2457 - accuracy: 0.0090 - val_loss: 0.1628 - val_accuracy: 0.0034\n",
      "Epoch 2/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1396 - accuracy: 0.0293 - val_loss: 0.1770 - val_accuracy: 0.0078\n",
      "Epoch 3/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1249 - accuracy: 0.0419 - val_loss: 0.1838 - val_accuracy: 0.0090\n",
      "Epoch 4/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1179 - accuracy: 0.0499 - val_loss: 0.1887 - val_accuracy: 0.0106\n",
      "Epoch 5/20\n",
      "279/279 [==============================] - 15s 52ms/step - loss: 0.1135 - accuracy: 0.0576 - val_loss: 0.1916 - val_accuracy: 0.0118\n",
      "Epoch 6/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1106 - accuracy: 0.0620 - val_loss: 0.1968 - val_accuracy: 0.0119\n",
      "Epoch 7/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1086 - accuracy: 0.0675 - val_loss: 0.1993 - val_accuracy: 0.0116\n",
      "Epoch 8/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.1067 - accuracy: 0.0727 - val_loss: 0.2025 - val_accuracy: 0.0126\n",
      "Epoch 9/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1053 - accuracy: 0.0711 - val_loss: 0.2050 - val_accuracy: 0.0124\n",
      "Epoch 10/20\n",
      "279/279 [==============================] - 14s 49ms/step - loss: 0.1043 - accuracy: 0.0717 - val_loss: 0.2074 - val_accuracy: 0.0142\n",
      "Epoch 11/20\n",
      "279/279 [==============================] - 14s 49ms/step - loss: 0.1032 - accuracy: 0.0788 - val_loss: 0.2099 - val_accuracy: 0.0144\n",
      "Epoch 12/20\n",
      "279/279 [==============================] - 15s 54ms/step - loss: 0.1024 - accuracy: 0.0815 - val_loss: 0.2119 - val_accuracy: 0.0145\n",
      "Epoch 13/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1020 - accuracy: 0.0813 - val_loss: 0.2166 - val_accuracy: 0.0124\n",
      "Epoch 14/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1013 - accuracy: 0.0821 - val_loss: 0.2176 - val_accuracy: 0.0172\n",
      "Epoch 15/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1010 - accuracy: 0.0862 - val_loss: 0.2197 - val_accuracy: 0.0138\n",
      "Epoch 16/20\n",
      "279/279 [==============================] - 13s 48ms/step - loss: 0.1000 - accuracy: 0.0891 - val_loss: 0.2225 - val_accuracy: 0.0144\n",
      "Epoch 17/20\n",
      "279/279 [==============================] - 15s 55ms/step - loss: 0.0996 - accuracy: 0.0893 - val_loss: 0.2231 - val_accuracy: 0.0145\n",
      "Epoch 18/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.0991 - accuracy: 0.0899 - val_loss: 0.2231 - val_accuracy: 0.0155\n",
      "Epoch 19/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.0984 - accuracy: 0.0930 - val_loss: 0.2288 - val_accuracy: 0.0187\n",
      "Epoch 20/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.0982 - accuracy: 0.0952 - val_loss: 0.2258 - val_accuracy: 0.0187\n",
      "467/467 [==============================] - 2s 4ms/step - loss: 0.2283 - accuracy: 0.0140\n",
      "try 1/5 Best_val_acc: [0.22829441726207733, 0.014007103629410267], lr: 0.19824709800893578, Lambda: 3.600355662289405e-05\n",
      " \n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "279/279 [==============================] - 15s 51ms/step - loss: 0.8668 - accuracy: 0.0141 - val_loss: 0.7426 - val_accuracy: 0.0174\n",
      "Epoch 2/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.7962 - accuracy: 0.0145 - val_loss: 0.7227 - val_accuracy: 0.0167\n",
      "Epoch 3/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.7168 - accuracy: 0.0169 - val_loss: 0.6445 - val_accuracy: 0.0169\n",
      "Epoch 4/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.6217 - accuracy: 0.0174 - val_loss: 0.5448 - val_accuracy: 0.0164\n",
      "Epoch 5/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.5137 - accuracy: 0.0173 - val_loss: 0.4414 - val_accuracy: 0.0132\n",
      "Epoch 6/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.4109 - accuracy: 0.0148 - val_loss: 0.3511 - val_accuracy: 0.0115\n",
      "Epoch 7/20\n",
      "279/279 [==============================] - 15s 52ms/step - loss: 0.3282 - accuracy: 0.0132 - val_loss: 0.2858 - val_accuracy: 0.0079\n",
      "Epoch 8/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.2714 - accuracy: 0.0117 - val_loss: 0.2437 - val_accuracy: 0.0073\n",
      "Epoch 9/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.2338 - accuracy: 0.0098 - val_loss: 0.2167 - val_accuracy: 0.0060\n",
      "Epoch 10/20\n",
      "279/279 [==============================] - 14s 49ms/step - loss: 0.2098 - accuracy: 0.0090 - val_loss: 0.2001 - val_accuracy: 0.0056\n",
      "Epoch 11/20\n",
      "279/279 [==============================] - 13s 45ms/step - loss: 0.1943 - accuracy: 0.0078 - val_loss: 0.1889 - val_accuracy: 0.0049\n",
      "Epoch 12/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1835 - accuracy: 0.0099 - val_loss: 0.1818 - val_accuracy: 0.0047\n",
      "Epoch 13/20\n",
      "279/279 [==============================] - 14s 49ms/step - loss: 0.1758 - accuracy: 0.0085 - val_loss: 0.1766 - val_accuracy: 0.0047\n",
      "Epoch 14/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1702 - accuracy: 0.0099 - val_loss: 0.1732 - val_accuracy: 0.0050\n",
      "Epoch 15/20\n",
      "279/279 [==============================] - 15s 52ms/step - loss: 0.1662 - accuracy: 0.0097 - val_loss: 0.1702 - val_accuracy: 0.0053\n",
      "Epoch 16/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1624 - accuracy: 0.0088 - val_loss: 0.1680 - val_accuracy: 0.0052\n",
      "Epoch 17/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1596 - accuracy: 0.0093 - val_loss: 0.1665 - val_accuracy: 0.0055\n",
      "Epoch 18/20\n",
      "279/279 [==============================] - 15s 55ms/step - loss: 0.1571 - accuracy: 0.0099 - val_loss: 0.1650 - val_accuracy: 0.0052\n",
      "Epoch 19/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.1551 - accuracy: 0.0104 - val_loss: 0.1640 - val_accuracy: 0.0050\n",
      "Epoch 20/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1530 - accuracy: 0.0111 - val_loss: 0.1630 - val_accuracy: 0.0053\n",
      "467/467 [==============================] - 2s 4ms/step - loss: 0.1634 - accuracy: 0.0038\n",
      "try 2/5 Best_val_acc: [0.16339702904224396, 0.0037530995905399323], lr: 0.002492495254098599, Lambda: 0.00023408814343509976\n",
      " \n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "279/279 [==============================] - 16s 54ms/step - loss: 0.4104 - accuracy: 0.0095 - val_loss: 0.1611 - val_accuracy: 0.0026\n",
      "Epoch 2/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1545 - accuracy: 0.0105 - val_loss: 0.1578 - val_accuracy: 0.0065\n",
      "Epoch 3/20\n",
      "279/279 [==============================] - 15s 55ms/step - loss: 0.1397 - accuracy: 0.0174 - val_loss: 0.1565 - val_accuracy: 0.0072\n",
      "Epoch 4/20\n",
      "279/279 [==============================] - 14s 49ms/step - loss: 0.1311 - accuracy: 0.0225 - val_loss: 0.1561 - val_accuracy: 0.0086\n",
      "Epoch 5/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1252 - accuracy: 0.0272 - val_loss: 0.1563 - val_accuracy: 0.0089\n",
      "Epoch 6/20\n",
      "279/279 [==============================] - 15s 52ms/step - loss: 0.1206 - accuracy: 0.0326 - val_loss: 0.1569 - val_accuracy: 0.0078\n",
      "Epoch 7/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.1170 - accuracy: 0.0366 - val_loss: 0.1576 - val_accuracy: 0.0078\n",
      "Epoch 8/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1141 - accuracy: 0.0400 - val_loss: 0.1586 - val_accuracy: 0.0078\n",
      "Epoch 9/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1116 - accuracy: 0.0439 - val_loss: 0.1597 - val_accuracy: 0.0082\n",
      "Epoch 10/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1096 - accuracy: 0.0465 - val_loss: 0.1601 - val_accuracy: 0.0101\n",
      "Epoch 11/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1080 - accuracy: 0.0487 - val_loss: 0.1612 - val_accuracy: 0.0089\n",
      "Epoch 12/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1063 - accuracy: 0.0527 - val_loss: 0.1624 - val_accuracy: 0.0096\n",
      "Epoch 13/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1051 - accuracy: 0.0542 - val_loss: 0.1634 - val_accuracy: 0.0103\n",
      "Epoch 14/20\n",
      "279/279 [==============================] - 14s 49ms/step - loss: 0.1038 - accuracy: 0.0555 - val_loss: 0.1640 - val_accuracy: 0.0106\n",
      "Epoch 15/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.1027 - accuracy: 0.0580 - val_loss: 0.1648 - val_accuracy: 0.0101\n",
      "Epoch 16/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1017 - accuracy: 0.0615 - val_loss: 0.1657 - val_accuracy: 0.0108\n",
      "Epoch 17/20\n",
      "279/279 [==============================] - 15s 54ms/step - loss: 0.1010 - accuracy: 0.0619 - val_loss: 0.1665 - val_accuracy: 0.0112\n",
      "Epoch 18/20\n",
      "279/279 [==============================] - 15s 52ms/step - loss: 0.1003 - accuracy: 0.0646 - val_loss: 0.1673 - val_accuracy: 0.0122\n",
      "Epoch 19/20\n",
      "279/279 [==============================] - 15s 54ms/step - loss: 0.0995 - accuracy: 0.0651 - val_loss: 0.1681 - val_accuracy: 0.0122\n",
      "Epoch 20/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.0988 - accuracy: 0.0678 - val_loss: 0.1693 - val_accuracy: 0.0113\n",
      "467/467 [==============================] - 2s 4ms/step - loss: 0.1703 - accuracy: 0.0099\n",
      "try 3/5 Best_val_acc: [0.17025457322597504, 0.00985188689082861], lr: 0.04007974864969444, Lambda: 0.0006289174003461205\n",
      " \n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "279/279 [==============================] - 15s 52ms/step - loss: 0.8635 - accuracy: 0.0141 - val_loss: 0.7394 - val_accuracy: 0.0155\n",
      "Epoch 2/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.7849 - accuracy: 0.0153 - val_loss: 0.7115 - val_accuracy: 0.0159\n",
      "Epoch 3/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.6951 - accuracy: 0.0165 - val_loss: 0.6209 - val_accuracy: 0.0164\n",
      "Epoch 4/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.5851 - accuracy: 0.0164 - val_loss: 0.5081 - val_accuracy: 0.0142\n",
      "Epoch 5/20\n",
      "279/279 [==============================] - 13s 46ms/step - loss: 0.4674 - accuracy: 0.0157 - val_loss: 0.3968 - val_accuracy: 0.0121\n",
      "Epoch 6/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.3639 - accuracy: 0.0139 - val_loss: 0.3128 - val_accuracy: 0.0105\n",
      "Epoch 7/20\n",
      "279/279 [==============================] - 16s 56ms/step - loss: 0.2896 - accuracy: 0.0129 - val_loss: 0.2566 - val_accuracy: 0.0083\n",
      "Epoch 8/20\n",
      "279/279 [==============================] - 16s 56ms/step - loss: 0.2421 - accuracy: 0.0104 - val_loss: 0.2231 - val_accuracy: 0.0060\n",
      "Epoch 9/20\n",
      "279/279 [==============================] - 16s 56ms/step - loss: 0.2132 - accuracy: 0.0092 - val_loss: 0.2029 - val_accuracy: 0.0053\n",
      "Epoch 10/20\n",
      "279/279 [==============================] - 13s 47ms/step - loss: 0.1953 - accuracy: 0.0092 - val_loss: 0.1903 - val_accuracy: 0.0040\n",
      "Epoch 11/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1832 - accuracy: 0.0091 - val_loss: 0.1821 - val_accuracy: 0.0042\n",
      "Epoch 12/20\n",
      "279/279 [==============================] - 15s 54ms/step - loss: 0.1751 - accuracy: 0.0088 - val_loss: 0.1767 - val_accuracy: 0.0039\n",
      "Epoch 13/20\n",
      "279/279 [==============================] - 15s 55ms/step - loss: 0.1696 - accuracy: 0.0098 - val_loss: 0.1730 - val_accuracy: 0.0043\n",
      "Epoch 14/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1647 - accuracy: 0.0094 - val_loss: 0.1703 - val_accuracy: 0.0040\n",
      "Epoch 15/20\n",
      "279/279 [==============================] - 15s 54ms/step - loss: 0.1613 - accuracy: 0.0105 - val_loss: 0.1680 - val_accuracy: 0.0046\n",
      "Epoch 16/20\n",
      "279/279 [==============================] - 15s 56ms/step - loss: 0.1583 - accuracy: 0.0110 - val_loss: 0.1662 - val_accuracy: 0.0050\n",
      "Epoch 17/20\n",
      "279/279 [==============================] - 15s 55ms/step - loss: 0.1558 - accuracy: 0.0120 - val_loss: 0.1650 - val_accuracy: 0.0047\n",
      "Epoch 18/20\n",
      "279/279 [==============================] - 15s 55ms/step - loss: 0.1535 - accuracy: 0.0111 - val_loss: 0.1638 - val_accuracy: 0.0047\n",
      "Epoch 19/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.1517 - accuracy: 0.0119 - val_loss: 0.1628 - val_accuracy: 0.0047\n",
      "Epoch 20/20\n",
      "279/279 [==============================] - 14s 52ms/step - loss: 0.1503 - accuracy: 0.0118 - val_loss: 0.1619 - val_accuracy: 0.0050\n",
      "467/467 [==============================] - 2s 4ms/step - loss: 0.1622 - accuracy: 0.0049\n",
      "try 4/5 Best_val_acc: [0.16224215924739838, 0.004892433527857065], lr: 0.0027454679108245, Lambda: 0.0001218628642904452\n",
      " \n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "279/279 [==============================] - 15s 52ms/step - loss: 0.5513 - accuracy: 0.0116 - val_loss: 0.2004 - val_accuracy: 0.0027\n",
      "Epoch 2/20\n",
      "279/279 [==============================] - 16s 58ms/step - loss: 0.1779 - accuracy: 0.0074 - val_loss: 0.1644 - val_accuracy: 0.0045\n",
      "Epoch 3/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1518 - accuracy: 0.0112 - val_loss: 0.1591 - val_accuracy: 0.0049\n",
      "Epoch 4/20\n",
      "279/279 [==============================] - 15s 55ms/step - loss: 0.1423 - accuracy: 0.0148 - val_loss: 0.1567 - val_accuracy: 0.0062\n",
      "Epoch 5/20\n",
      "279/279 [==============================] - 15s 56ms/step - loss: 0.1357 - accuracy: 0.0196 - val_loss: 0.1554 - val_accuracy: 0.0060\n",
      "Epoch 6/20\n",
      "279/279 [==============================] - 15s 54ms/step - loss: 0.1308 - accuracy: 0.0221 - val_loss: 0.1552 - val_accuracy: 0.0065\n",
      "Epoch 7/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1270 - accuracy: 0.0250 - val_loss: 0.1550 - val_accuracy: 0.0067\n",
      "Epoch 8/20\n",
      "279/279 [==============================] - 15s 54ms/step - loss: 0.1236 - accuracy: 0.0271 - val_loss: 0.1551 - val_accuracy: 0.0075\n",
      "Epoch 9/20\n",
      "279/279 [==============================] - 15s 55ms/step - loss: 0.1212 - accuracy: 0.0303 - val_loss: 0.1554 - val_accuracy: 0.0082\n",
      "Epoch 10/20\n",
      "279/279 [==============================] - 15s 54ms/step - loss: 0.1185 - accuracy: 0.0320 - val_loss: 0.1558 - val_accuracy: 0.0072\n",
      "Epoch 11/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1164 - accuracy: 0.0356 - val_loss: 0.1561 - val_accuracy: 0.0088\n",
      "Epoch 12/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1147 - accuracy: 0.0388 - val_loss: 0.1564 - val_accuracy: 0.0083\n",
      "Epoch 13/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1131 - accuracy: 0.0378 - val_loss: 0.1570 - val_accuracy: 0.0079\n",
      "Epoch 14/20\n",
      "279/279 [==============================] - 15s 53ms/step - loss: 0.1116 - accuracy: 0.0425 - val_loss: 0.1575 - val_accuracy: 0.0079\n",
      "Epoch 15/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1103 - accuracy: 0.0436 - val_loss: 0.1580 - val_accuracy: 0.0086\n",
      "Epoch 16/20\n",
      "279/279 [==============================] - 14s 49ms/step - loss: 0.1093 - accuracy: 0.0463 - val_loss: 0.1587 - val_accuracy: 0.0089\n",
      "Epoch 17/20\n",
      "279/279 [==============================] - 15s 54ms/step - loss: 0.1080 - accuracy: 0.0450 - val_loss: 0.1591 - val_accuracy: 0.0083\n",
      "Epoch 18/20\n",
      "279/279 [==============================] - 14s 50ms/step - loss: 0.1070 - accuracy: 0.0474 - val_loss: 0.1595 - val_accuracy: 0.0098\n",
      "Epoch 19/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1060 - accuracy: 0.0506 - val_loss: 0.1600 - val_accuracy: 0.0088\n",
      "Epoch 20/20\n",
      "279/279 [==============================] - 14s 51ms/step - loss: 0.1052 - accuracy: 0.0522 - val_loss: 0.1607 - val_accuracy: 0.0090\n",
      "467/467 [==============================] - 2s 4ms/step - loss: 0.1616 - accuracy: 0.0076\n",
      "try 5/5 Best_val_acc: [0.1616000384092331, 0.007640238385647535], lr: 0.02300922492086118, Lambda: 5.52966383334382e-05\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for i in range (1,6):\n",
    "    lr = math.pow(10, np.random.uniform(-4.0, 0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5,-3))\n",
    "    acc,model_sgd = train_test_model( Lambda,lr, 20)\n",
    "    print(\"try {0}/{1} Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n \".format(i,5 ,acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xEDaeXdmery0",
    "outputId": "1fa16510-54a8-48ed-e859-8f8724d02831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 200, 50)           6296800   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10000)             40000     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                800080    \n",
      "=================================================================\n",
      "Total params: 7,136,880\n",
      "Trainable params: 7,116,880\n",
      "Non-trainable params: 20,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sgd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Tc2wEamLsQv",
    "outputId": "9e9d95f8-e7d7-4c47-b710-8cb721dabdc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467/467 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.0074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15855392813682556, 0.007372159976512194]"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sgd.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7M0vS8pGSuq"
   },
   "source": [
    "### 4. Display and explain in detail the classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3anmboV77NDw"
   },
   "source": [
    "##### Comparing all the accuracies and F1 score, TF-IDF vectorization along with logistic regression model provides us the best score, so we will use the model to predict authors' features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "cSiKsX-TMw9i"
   },
   "outputs": [],
   "source": [
    "#logModel=OneVsRestClassifier(logRegression)\n",
    "#logModel.fit(X_train_scale,y_train)\n",
    "log_predict = rs_lr.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "yVOdw6_wNkFS"
   },
   "outputs": [],
   "source": [
    "y_test_inv = binarizer.inverse_transform(y_test)\n",
    "log_predict_inv= binarizer.inverse_transform(log_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q40kRmrEGy5M",
    "outputId": "b12eab3b-2a44-4d25-a3d3-760b22c1c4fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.1538100663494404\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.18      0.30       218\n",
      "           1       0.81      0.17      0.29       646\n",
      "           2       0.73      0.23      0.35      1041\n",
      "           3       0.85      0.21      0.34      1219\n",
      "           4       0.80      0.28      0.41      2062\n",
      "           5       0.76      0.20      0.31      1650\n",
      "           6       0.75      0.28      0.41      1693\n",
      "           7       0.75      0.07      0.13       864\n",
      "           8       0.88      0.10      0.18       805\n",
      "           9       0.77      0.19      0.30      1196\n",
      "          10       0.57      0.12      0.20       514\n",
      "          11       0.95      0.59      0.72       563\n",
      "          12       0.60      0.34      0.43      1031\n",
      "          13       0.93      0.44      0.60       620\n",
      "          14       0.83      0.05      0.10        93\n",
      "          15       0.67      0.07      0.12        60\n",
      "          16       0.83      0.15      0.25       101\n",
      "          17       0.44      0.12      0.19        56\n",
      "          18       0.79      0.23      0.36       116\n",
      "          19       0.00      0.00      0.00        32\n",
      "          20       1.00      0.11      0.20        36\n",
      "          21       0.00      0.00      0.00        13\n",
      "          22       1.00      0.10      0.19        29\n",
      "          23       1.00      0.06      0.12       114\n",
      "          24       1.00      0.10      0.18        60\n",
      "          25       1.00      0.19      0.32        89\n",
      "          26       0.00      0.00      0.00        69\n",
      "          27       0.88      0.49      0.63        76\n",
      "          28       0.00      0.00      0.00        31\n",
      "          29       0.80      0.30      0.44      1418\n",
      "          30       0.00      0.00      0.00        21\n",
      "          31       0.70      0.33      0.45      2346\n",
      "          32       0.70      0.11      0.19       564\n",
      "          33       0.80      0.11      0.19        37\n",
      "          34       0.90      0.12      0.20        78\n",
      "          35       1.00      0.03      0.07        29\n",
      "          36       0.91      0.19      0.32       109\n",
      "          37       0.72      0.19      0.30      1369\n",
      "          38       0.80      0.32      0.46      1116\n",
      "          39       1.00      0.04      0.07        26\n",
      "          40       0.64      0.08      0.13       465\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       1.00      0.07      0.12        61\n",
      "          43       0.83      0.37      0.51       769\n",
      "          44       0.84      0.35      0.50       423\n",
      "          45       0.00      0.00      0.00         3\n",
      "          46       0.88      0.49      0.63       577\n",
      "          47       0.85      0.12      0.21       774\n",
      "          48       0.74      0.12      0.21       165\n",
      "          49       1.00      0.15      0.26        27\n",
      "          50       0.71      0.11      0.18       435\n",
      "          51       0.79      0.55      0.65        20\n",
      "          52       1.00      0.07      0.13       102\n",
      "          53       1.00      0.03      0.06        34\n",
      "          54       0.78      0.12      0.20      1162\n",
      "          55       0.81      0.31      0.45      1299\n",
      "          56       0.94      0.22      0.36       134\n",
      "          57       0.00      0.00      0.00        14\n",
      "          58       0.91      0.18      0.30       117\n",
      "          59       0.89      0.26      0.41        61\n",
      "          60       1.00      0.60      0.75        87\n",
      "          61       0.80      0.03      0.05       157\n",
      "          62       0.79      0.24      0.37      1224\n",
      "          63       1.00      0.04      0.09        67\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.45      0.16      0.23        83\n",
      "          66       0.90      0.24      0.37      1403\n",
      "          67       0.92      0.22      0.35       213\n",
      "          68       0.71      0.13      0.22       965\n",
      "          69       0.00      0.00      0.00        34\n",
      "          70       0.78      0.29      0.42      3223\n",
      "          71       0.63      0.08      0.14      1026\n",
      "          72       0.70      0.22      0.33      1289\n",
      "          73       0.00      0.00      0.00         4\n",
      "          74       0.00      0.00      0.00        20\n",
      "          75       1.00      0.03      0.06        61\n",
      "          76       0.63      0.08      0.14       819\n",
      "          77       0.69      0.69      0.69      7290\n",
      "          78       0.75      0.31      0.44      5223\n",
      "          79       0.78      0.56      0.65      7631\n",
      "\n",
      "   micro avg       0.75      0.34      0.47     59684\n",
      "   macro avg       0.70      0.18      0.26     59684\n",
      "weighted avg       0.76      0.34      0.44     59684\n",
      " samples avg       0.60      0.34      0.40     59684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \",accuracy_score(y_test,log_predict))\n",
    "print('Classification report:\\n',classification_report(y_test,log_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsD6ORvb4Loa"
   },
   "source": [
    "###### From the above classification report, we observe that F1 score is around 44%. The accuracy is not much since the classes are not even distributed but as per classification report, for almost all classes, prediction is done which means F1 score takes each class into account rather than accuracy as a whole.There are 80 classes including all ranges of ages, zodiac sign, topic and gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWzTekIlGfuB"
   },
   "source": [
    "### 5. Print the true vs predicted labels for any 5 entries from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XY6ffaZONuhB",
    "outputId": "c69a382b-9848-4023-d3c2-44f96cf09b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index : 100\n",
      "Acutal Label :  ('23', 'Pisces', 'Student', 'female')\n",
      "Predicted Label : ('23', 'Pisces', 'Student', 'female')\n",
      "\n",
      "Index : 101\n",
      "Acutal Label :  ('16', 'Taurus', 'female', 'indUnk')\n",
      "Predicted Label : ('16', 'male')\n",
      "\n",
      "Index : 102\n",
      "Acutal Label :  ('23', 'Scorpio', 'Student', 'female')\n",
      "Predicted Label : ('female', 'male')\n",
      "\n",
      "Index : 103\n",
      "Acutal Label :  ('14', 'Museums-Libraries', 'Scorpio', 'male')\n",
      "Predicted Label : ('14', 'Museums-Libraries', 'Scorpio', 'male')\n",
      "\n",
      "Index : 104\n",
      "Acutal Label :  ('36', 'Advertising', 'Cancer', 'female')\n",
      "Predicted Label : ()\n",
      "\n",
      "Index : 105\n",
      "Acutal Label :  ('35', 'Aries', 'Technology', 'male')\n",
      "Predicted Label : ('female',)\n",
      "\n",
      "Index : 106\n",
      "Acutal Label :  ('15', 'Gemini', 'Student', 'male')\n",
      "Predicted Label : ('male',)\n",
      "\n",
      "Index : 107\n",
      "Acutal Label :  ('34', 'Aquarius', 'Education', 'male')\n",
      "Predicted Label : ('34', 'Aquarius', 'Education', 'male')\n",
      "\n",
      "Index : 108\n",
      "Acutal Label :  ('35', 'Cancer', 'Technology', 'male')\n",
      "Predicted Label : ('female',)\n",
      "\n",
      "Index : 109\n",
      "Acutal Label :  ('24', 'Aries', 'indUnk', 'male')\n",
      "Predicted Label : ('male',)\n",
      "\n",
      "Index : 110\n",
      "Acutal Label :  ('24', 'Scorpio', 'female', 'indUnk')\n",
      "Predicted Label : ('23', '24', 'Scorpio', 'female', 'indUnk')\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,111):\n",
    "  print(\"\\nIndex :\",i)\n",
    "  print(\"Acutal Label : \",y_test_inv[i])\n",
    "  print(\"Predicted Label :\",log_predict_inv[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXzHpnrH5jOV"
   },
   "source": [
    "##### From above predicted values we see that out of 3/10 predictions are correct( indices 100,103,107), 5 /10 are partially predicted (indices 101, 102, 110, 106,109) and 2/10 were not predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHuzFw-2IrAJ"
   },
   "source": [
    "### Conclusion/Observation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2ng5zduIaWl"
   },
   "source": [
    "1. Bag of words\n",
    "\n",
    "\n",
    "| Model/metrics|Accuracy|F1 Score |\n",
    "|:---:|:-------------:|:-----------:|\n",
    "| Logistic Regression|0.12|0.19|\n",
    "| K-Nearest Neighbour|0.028|0.05|\n",
    "| Naive Bayes|0.035|0.05|\n",
    "| Random Forest classifier | 0.037|0.054|\n",
    "|Decision Tree |0.067|0.22|\n",
    " \n",
    "With Hyperparameter tuning\n",
    "\n",
    "| Model/metrics|Accuracy|F1 Score |\n",
    "|:---:|:-------------:|:-----------:|\n",
    "| Logistic Regression|0.05|0.396|\n",
    "| Naive Bayes|0.031|0.245|\n",
    "|Random Forest classifier | 0.049|0.267|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. TF-IDF \n",
    "\n",
    "\n",
    "| Model/metrics|Accuracy|F1 Score |\n",
    "|:---:|:-------------:|:-----------:|\n",
    "| Logistic Regression|0.17|0.28|\n",
    "| K-Nearest Neighbour| 0.024|0.040|\n",
    "| Naive Bayes|0.107|0.14|\n",
    "| Random Forest classifier |0.049|0.114|\n",
    "|Decision Tree |0.066| 0.257|\n",
    "\n",
    "\n",
    "With Hyperparameter tuning\n",
    "\n",
    " | Model/metrics|Accuracy|F1 Score |\n",
    "|:---:|:-------------:|:-----------:|\n",
    "| Logistic Regression|0.15|0.44|\n",
    "| Naive Bayes|0.107|0.37|\n",
    "| Random Forest classifier |0.03|0.26|\n",
    "\n",
    "\n",
    "\n",
    "3. From the above task , we were able to predict authors' features from blog text using multi-label classification.We were able to preprocess , vectorize and use the text data as indepedent feature for machine learning algorithm. The multi-labels were transformed to single multi-class targets and binarized. Since the target is in logical format , logistic regression is able to perform the best.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MultiLabelBlogClassification_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
